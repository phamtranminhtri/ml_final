\documentclass[10pt,a4paper]{article}

% ---------------- Packages ----------------
\usepackage[utf8]{inputenc}
\usepackage[T5]{fontenc}
\usepackage[vietnamese]{babel}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{multicol}

\geometry{margin=0.5cm}
\setlength{\parindent}{0pt}
\usepackage{titlesec}
\titlespacing*{\section}{0pt}{0em}{0em}
% \everymath{\displaystyle}


\begin{document}

\begin{multicols}{3}

% SECTION 1: LINEAR REGRESSION

\section{Linear regression}

Mô hình:
$
\hat{y}(\mathbf{x}, \mathbf{w}) = \mathbf{w}^T \mathbf{x}
$


\textbf{Hợp lý cực đại}


$
p(t_n | \mathbf{x}_n, \mathbf{w}, \beta)
= \mathcal{N}(t_n | \mathbf{w}^T \mathbf{x}_n, \beta^{-1})
$

$
L(\mathbf{w}, \beta)
= \beta E_D(\mathbf{w})
- \frac{N}{2} \log \beta
+ \frac{N}{2} \log(2\pi)
$

với:
$
E_D(\mathbf{w})
= \frac{1}{2}\sum_{n=1}^N (t_n - \mathbf{w}^T \mathbf{x}_n)^2
$

\textbf{Nghiệm giải tích}

Cực tiểu $E_D(\mathbf{w})$:
$
\mathbf{w}_{ML} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{t}
$

$
\beta_{ML}^{-1}
= \frac{1}{N}\sum_{n=1}^N
(t_n - \mathbf{w}_{ML}^T\mathbf{x}_n)^2
$

\textbf{Giải thuật lặp (Gradient Descent)}


$
\mathbf{w}^{(t)}
= \mathbf{w}^{(t-1)} - \eta \nabla E_D(\mathbf{w})
$

% =====================================================
\textbf{Hồi quy cho quan hệ phi tuyến}

$
\mathbf{x} \rightarrow
\boldsymbol{\phi}(\mathbf{x})
= [\phi_0(\mathbf{x}), \dots, \phi_{M-1}(\mathbf{x})]
$


% =====================================================
\textbf{Đánh giá mô hình}

\textbf{Dự báo:}
$
\hat{\mathbf{y}} = \mathbf{X}\mathbf{w}_{ML}
$

\textbf{Các độ đo}

$
\mathrm{MSE}
= \frac{1}{N}\sum_{n=1}^N (t_n - \hat{y}_n)^2
$

$
\mathrm{RMSE} = \sqrt{\mathrm{MSE}}
$

% =====================================================
\textbf{Hạn chế quá khớp}

\textbf{Ridge Regression}

$
L(\mathbf{w})
= \frac{1}{2}\sum_{n=1}^N (t_n - \mathbf{w}^T\mathbf{x}_n)^2
+ \frac{\lambda}{2}\mathbf{w}^T\mathbf{w}
$

Nghiệm:
$
\mathbf{w}_{ridge}
= (\lambda \mathbf{I} + \mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{t}
$

\textbf{LASSO:}
$
L(\mathbf{w})
= \frac{1}{2}\sum_{n=1}^N (t_n - \mathbf{w}^T\mathbf{x}_n)^2
+ \lambda \sum_{m=1}^M |w_m|
$

% =====================================================
\textbf{Dự báo cho nhiều biến}

Với $K$ biến đầu ra:
$
\mathbf{W}
= (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{T}
$

Trong đó:
 $\mathbf{T} \in \mathbb{R}^{N \times K}, \mathbf{W} \in \mathbb{R}^{M \times K}$

% SECTION 2: LOGISTIC REGRESSION
% ==================================================
\section{Logistic regression}



\textbf{Hàm sigmoid:}
$
\sigma(z) = \frac{1}{1 + e^{-z}}
$

\textbf{Mô hình dự báo:}

$
\hat{y} = p(C_1|x,w) = \sigma(w^T x)
\label{eq:logistic}
$

Nếu $\hat{y} \ge \lambda$ thì $x \in C_1$.
Ngược lại, $x \in C_0$

% ==================================================
\textbf{Ước lượng tham số của mô hình}

\textbf{Xây dựng hàm mục tiêu}

Với một điểm dữ liệu $(x,y)$:

$
p(y|x,w) =
\hat{y}^y (1-\hat{y})^{1-y}
$

Với $N$ điểm dữ liệu:

$
p(t|X,w) = \prod_{n=1}^{N} \hat{y}_n^{y_n} (1-\hat{y}_n)^{1-y_n}
$

\textbf{Negative log-likelihood}:
$
L(w) = -\sum_{n=1}^{N}
[
y_n \log \hat{y}_n + (1-y_n)\log(1-\hat{y}_n)
]
$

Hàm này còn được gọi là \textbf{cross-entropy}.

\textbf{Tìm hệ số của mô hình}

$
\nabla L(w) = \sum_{n=1}^{N} (\hat{y}_n - y_n)x_n
= X^T(\hat{y} - y)
$

\textbf{Giải thuật lặp với đạo hàm bậc 2}

Ma trận Hessian:
$
H = \nabla^2 L(w)
= \sum_{n=1}^{N} \hat{y}_n(1-\hat{y}_n)x_n x_n^T
= X^T R X
$

$R$ là ma trận đường chéo:
$
R_{nn} = \hat{y}_n(1-\hat{y}_n)
$

Phương pháp sử dụng: Gradient Descent, Newton--Raphson, Iterative Re-weighted Least Squares (IRLS)

% SECTION 3: SOFTMAX REGRESSION


% ==================================================
\section{Softmax regression}

Mỗi nhãn được mã hóa dưới dạng véctơ one-hot kích thước $K$.
% ==================================================

\textbf{Mô hình tuyến tính với Softmax}

\textbf{Mô hình dự báo}

Ma trận tham số của mô hình:

$
W =
[w_1,
w_2,
\ldots
w_K]^T
\in \mathbb{R}^{K \times M}
$

Các bước tính toán:
$
Z = XW^T \quad (N \times K), \\
\hat{Y} = \text{softmax}(Z)
$

Hàm softmax:
$
\hat{y}_k = \frac{\exp(z_k)}{\sum_{i=1}^{K} \exp(z_i)}
$

\textbf{Dự đoán}

Nhãn dự đoán:
$
\text{prediction} = \arg\max_k \hat{y}_k
$

% ==================================================
\textbf{Hàm mục tiêu và tối ưu}

\textbf{Hàm hợp lý}

Xác suất của tập nhãn:

$
p(t|X,W) = \prod_{n=1}^{N} \prod_{k=1}^{K} \hat{y}_{n,k}^{y_{n,k}}
$

\textbf{Hàm mất mát Cross-Entropy}

Hàm mất mát được xây dựng bằng cách lấy log và đổi dấu:

$
L(W) = -\sum_{n=1}^{N}\sum_{k=1}^{K} y_{n,k}\log(\hat{y}_{n,k})
$

Mục tiêu là tìm $W$ sao cho $L(W)$ đạt giá trị nhỏ nhất.

% ==================================================
\textbf{Ước lượng tham số}

\textbf{Gradient Descent}

Gradient của hàm mất mát đối với đầu vào softmax:
$
\frac{\partial L}{\partial z} = (\hat{y} - y)^T
$

Gradient theo tham số:
$
\Delta W = (\hat{y} - y)^T x^T
$

Cập nhật trọng số:
$
W \leftarrow W - \eta \Delta W
$


% ==================================================



% SECTION 4: MLP
% ======================================================
\section{MLP}


\textbf{Core idea:}
deep learning = nonlinear feature extraction + simple linear head.

% ======================================================

\textbf{Forward Pass}

Let $h^{(0)} = x$; 
$
h^{(l)} = \phi\left(W^{(l)}h^{(l-1)} + b^{(l)}\right),
\\ l = 1,\dots,L
$
where $\phi(\cdot)$ is a nonlinear activation function.

\textbf{Output Layer}

\textbf{Regression:}
$
\hat{y} = W^{(L+1)}h^{(L)} + b^{(L+1)}
$

\textbf{Classification:}
$
\hat{p}_k =
\frac{\exp(w_k^\top h^{(L)} + b_k)}
{\sum_{j}\exp(w_j^\top h^{(L)} + b_j)}
$

\textbf{Function Composition View}

$
f(x;\theta) =
f^{(L+1)} \circ \phi \circ f^{(L)} \circ \cdots \circ \phi \circ f^{(1)}(x)
$


\textbf{Fully Connected (Linear) Layer}

Single sample:
$
y = Wx + b
$

Mini-batch $X \in \mathbb{R}^{B \times N}$:
$
Y = XW^\top + \mathbf{1}b^\top
$

\textbf{Activation Functions}

Sigmoid:
$
\sigma(z)=\frac{1}{1+e^{-z}}
$

Tanh:
$
\tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}
$

ReLU:
$
\mathrm{ReLU}(z)=\max(0,z)
$

Leaky ReLU:
$
\mathrm{LReLU}(z)=
\begin{cases}
z, & z\ge 0\\
\alpha z, & z<0
\end{cases}
$

SiLU (Swish):
$
\mathrm{SiLU}(z)=z\sigma(z)
$

% SECTION 5: TRAINING ANN
\section{Training ANN}

\textbf{Problem Setup}
Given a dataset $\{(x_i, y_i)\}_{i=1}^n$ and a model
$\hat{y}_i = f_\theta(x_i)$, training aims to solve:

$
\min_{\theta} \; L(\theta) = \frac{1}{n}\sum_{i=1}^n \ell(y_i, \hat{y}_i).
$

\textbf{Regression Losses:}

$
L_{\text{MSE}} = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2.
$

$
L_{\text{MAE}} = \frac{1}{n}\sum_{i=1}^n |y_i - \hat{y}_i|.
$

Huber Loss:

$
L_\delta(e_i) =
\begin{cases}
\frac{1}{2}e_i^2, & |e_i| \le \delta, \\
\delta(|e_i| - \frac{1}{2}\delta), & |e_i| > \delta,
\end{cases}
$

where $e_i = y_i - \hat{y}_i$.

\textbf{Classification Losses}

BCE:
For $y_i \in \{0,1\}$ and $p_i = \sigma(z_i)$:
$
L_{\text{BCE}} = -\frac{1}{n}\sum_{i=1}^n
[y_i \log p_i + (1-y_i)\log(1-p_i)].
$

Categorical Cross-Entropy:
For $K$ classes with one-hot labels:

$
L_{\text{CE}} = -\frac{1}{n}\sum_{i=1}^n \sum_{k=1}^K y_{ik}\log p_{ik}.
$

\textbf{Training Process:}

 {Forward}: compute predictions and loss.

 {Backward}: compute grads via backprop.

 {Update}: update param with optimizer.


\textbf{SGD:}
$
\theta \leftarrow \theta - \eta \nabla_\theta L.
$

\textbf{Training Algorithm}
\begin{algorithm}[H]
\caption{SGD Training Procedure}
\begin{algorithmic}[1]
\STATE Initialize parameters $\theta$
\FOR{epoch = 1 to $E$}
    \STATE Shuffle dataset and create mini-batches
    \FOR{each mini-batch $(X,y)$}
        \STATE Forward pass
        \STATE Compute loss $L$
        \STATE Backward pass: compute $\nabla_\theta L$
        \STATE Update: $\theta \leftarrow \theta - \eta \nabla_\theta L$
    \ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}

\textbf{SGD with Momentum:}

$
v_t = \mu v_{t-1} + g_t, \quad
\theta \leftarrow \theta - \eta v_t.
$

\textbf{Adam:}
$
m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t, \\
v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2, \\
\theta \leftarrow \theta - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t}+\epsilon}.
$

\textbf{AdamW:}
 decouples weight decay from the gradient update

% \textbf{Training Techniques:}

% {Learning Rate Scheduling:} step decay, cosine annealing,  warm restarts.

% {Regularization:}  L2 weight decay, Dropout,  Early stopping

% {Normalization:}
% Batch Normalization and Layer Normalization 

% \textbf{Practical Considerations:}

% {Init:}
% Xavier-sigmoid/tanh,  He-ReLU.

% Gradient Issues
% (Vanishing/exploding gradients): ReLU activations,
% residual connections,  gradient clipping.

% SECTION 6: SVM PRIMAL PROBLEM
\section{SVM primal problem}

\textbf{Đầu vào}

Ma trận dữ liệu:  $X \in \mathbb{R}^{N \times (M-1)}$.
    
Nhãn:
    $
    \mathbf{t} =
    [t_1, t_2,\ldots, t_N]^T,  t_n \in \{-1, +1\}
    $


\textbf{Mục tiêu}
Xác định đường biên quyết định:
$
\mathbf{w}^T \mathbf{x} + b = 0
$
sao cho \textbf{lề (margin)} giữa hai lớp là lớn nhất.


\textbf{Khoảng cách từ điểm đến đường thẳng}

Siêu phẳng trong không gian đặc trưng $(M-1)$ chiều:
$
\mathbf{w}^T \mathbf{x} + b = 0
$

Khoảng cách có dấu từ điểm $\mathbf{x}$ đến siêu phẳng:
$
d(\mathbf{x}) = \frac{\mathbf{w}^T \mathbf{x} + b}{\|\mathbf{w}\|}
$

Khoảng cách hình học:
$
|d(\mathbf{x})| = \frac{|\mathbf{w}^T \mathbf{x} + b|}{\|\mathbf{w}\|}
$

\textbf{Hàm quyết định:}
$
y(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b
$

Quy tắc phân lớp:
$
\text{class}(\mathbf{x}) = \text{sign}(y(\mathbf{x}))
$

\textbf{Lề (Margin):}
$
m_{\mathbf{w}} = \min_{n} \frac{t_n(\mathbf{w}^T \mathbf{x}_n + b)}{\|\mathbf{w}\|}
$

\textbf{Cực đại lề:}
Có thể chuẩn hóa sao cho:
$
t_n(\mathbf{w}^T \mathbf{x}_n + b) \ge 1, \quad \forall n
$

\textbf{Hàm mục tiêu}

Cực đại lề tương đương với bài toán:
$
\min_{\mathbf{w}, b} \frac{1}{2}\|\mathbf{w}\|^2
$
với ràng buộc:

$
t_n(\mathbf{w}^T \mathbf{x}_n + b) \ge 1, \quad n=1,\dots,N
$

\textbf{Bài toán gốc:}

$
\mathbf{w}^*, b^* = \arg\min_{\mathbf{w}, b} \quad 
\frac{1}{2}\|\mathbf{w}\|^2 \\
\text{s.t.} \quad 
t_n(\mathbf{w}^T \mathbf{x}_n + b) \ge 1,\quad \forall n
$

\textbf{Giải bằng thư viện CVXOPT}

Dạng chuẩn:
$
\min_{\mathbf{x}} \frac{1}{2}\mathbf{x}^T K \mathbf{x} + \mathbf{p}^T \mathbf{x}
\\ \text{s.t. } G\mathbf{x} \le \mathbf{h}
$.
Trong đó:
$
\mathbf{x} =
\begin{bmatrix}
\mathbf{w} \\ b
\end{bmatrix}
$


% SECTION 7: SVM DUAL PROBLEM

% =====================================================

% =====================================================
\section{SVM dual problem}


\textbf{Hàm Lagrangian}

Hàm Lagrangian của bài:
$
L(w,b,\alpha)
=
\frac{1}{2}\|w\|^2
-
\sum_{n=1}^N \alpha_n
\bigl[t_n(w^T x_n + b) - 1\bigr],
\label{eq:lagrangian}
$

với
$
\alpha_n \ge 0,\quad n=1,\dots,N.
$

\textbf{Điều kiện KKT}

\textbf{(KKT-1)} ĐK dừng:
$
\nabla_{w,b} L(w,b,\alpha)=0
$

\textbf{(KKT-2)} Ràng buộc gốc

 \textbf{(KKT-3)} Ràng buộc đối ngẫu: $\alpha_n \ge 0$

\textbf{(KKT-4)} ĐK bù:
$
\alpha_n[1-t_n(w^Tx_n+b)]=0
$

% =====================================================
\textbf{Xây dựng hàm đối ngẫu}

$
\frac{\partial L}{\partial w} = w - \sum_{n=1}^N \alpha_n t_n x_n = 0
\\
\frac{\partial L}{\partial b} = \sum_{n=1}^N \alpha_n t_n = 0
$

Suy ra:
$
w = \sum_{n=1}^N \alpha_n t_n x_n.
$

Thay vào Lagrangian, được hàm đối ngẫu:

$
g(\alpha)
=
\sum_{n=1}^N \alpha_n
-
\frac{1}{2}
\sum_{r=1}^N \sum_{c=1}^N
\alpha_r \alpha_c t_r t_c x_r^T x_c.
$

% =====================================================
\textbf{Bài toán đối ngẫu}

$
\alpha^\ast
= \arg\min_{\alpha}
\;\frac{1}{2}\alpha^T K \alpha - \mathbf{1}^T \alpha \\
\text{s.t. }
 \alpha_n \ge 0, n=1,\dots,N,
 \sum_{n=1}^N \alpha_n t_n = 0,
$
trong đó
$
K_{rc} = t_r t_c x_r^T x_c.
$

% =====================================================
\textbf{Tiêu chuẩn Slater}

Vì tồn tại $(w,b)$ sao cho
$
t_n(w^Tx_n+b) > 1,\;\forall n,
$
nên bài toán thỏa tiêu chuẩn Slater.
Do đó:
$
\min_{w,b} \max_{\alpha} L(w,b,\alpha)
=
\max_{\alpha} \min_{w,b} L(w,b,\alpha).
$

Suy ra \textbf{duality gap bằng 0}.

% =====================================================
\textbf{Công thức dự báo}

Với tập véc-tơ hỗ trợ $S = \{n : \alpha_n > 0\}$,
$
y(x)
=
\sum_{n\in S} \alpha_n t_n x_n^T x + b.
$

Nhãn dự báo:
$
\hat{y} = \operatorname{sign}(y(x)).
$



% SECTION 8: SVM SOFT MARGIN

%------------------------------------------------
\section{SVM soft margin}


\textbf{Ràng buộc mới}

\begin{align}
t_n(w^T x_n + b) &\ge 1 - \xi_n, \quad n=1,\dots,N, \\
\xi_n &\ge 0.
\end{align}

\textbf{Hàm mục tiêu mới}

$
f_0(w,b,\xi) =
\frac{1}{2}\|w\|^2 + C \sum_{n=1}^N \xi_n,
$
trong đó $C > 0$ là siêu tham số điều chỉnh mức phạt.

\textbf{Bài toán tối ưu}

$
\begin{aligned}
\min_{w,b,\xi} \quad &
\frac{1}{2}\|w\|^2 + C \sum_{n=1}^N \xi_n \\
\text{s.t.} \quad &
t_n(w^T x_n + b) \ge 1 - \xi_n, \\
& \xi_n \ge 0,\quad n=1,\dots,N.
\end{aligned}
$

%------------------------------------------------
\textbf{Bài toán đối ngẫu}

\textbf{Hàm Lagrangian}

$
\begin{aligned}
L(w,b,\xi,\alpha,\mu) &=
\frac{1}{2}\|w\|^2 + C\sum_{n=1}^N \xi_n \\
&\quad - \sum_{n=1}^N \alpha_n[t_n(w^T x_n + b)-1+\xi_n]
- \sum_{n=1}^N \mu_n \xi_n.
\end{aligned}
$

\textbf{Điều kiện KKT}

\begin{align}
w &= \sum_{n=1}^N \alpha_n t_n x_n, \\
\sum_{n=1}^N \alpha_n t_n &= 0, \\
0 &\le \alpha_n \le C.
\end{align}

\textbf{Bài toán đối ngẫu}

$
\begin{aligned}
\min_{\alpha} \quad &
\frac{1}{2}\sum_{r=1}^N\sum_{c=1}^N
\alpha_r \alpha_c t_r t_c x_r^T x_c
- \sum_{n=1}^N \alpha_n \\
\text{s.t.} \quad &
0 \le \alpha_n \le C, \\
& \sum_{n=1}^N \alpha_n t_n = 0.
\end{aligned}
$

%------------------------------------------------
\textbf{Công thức dự báo}

Sau khi tìm được $\alpha$ và $b$, hàm quyết định là:
$
y(x) = \sum_{n \in S} \alpha_n t_n x_n^T x + b,
$
trong đó $S$ là tập các véc-tơ hỗ trợ.

Nhãn dự báo:
$
\text{label} = \mathrm{sign}(y(x)).
$

%------------------------------------------------
\textbf{Cài đặt với CVXOPT}

Bài toán đối ngẫu có dạng chuẩn:
$
\min_{\alpha} \quad
\frac{1}{2}\alpha^T K \alpha + p^T \alpha
\quad \text{s.t.} \quad
G\alpha \le h,\; A\alpha = b.
$

Các ràng buộc hộp $0 \le \alpha_n \le C$ được mã hóa trong ma trận $G$ và $h$.

%------------------------------------------------

% SECTION 9: SVM KERNEL


\section{SVM kernel}

\textbf{SVM hai lớp với lề mềm}
Xét tập huấn luyện $\{(x_i,t_i)\}_{i=1}^N$ với $t_i \in \{-1,+1\}$.
Bài toán đối ngẫu của SVM lề mềm được viết dưới dạng:

$
\alpha^* = \arg\min_{\alpha}
\frac{1}{2}\alpha^T K \alpha + p^T \alpha
$

với các ràng buộc:
$
G\alpha \le h, \qquad A\alpha = b
$

Trong đó, ma trận kernel $K$ được xác định bởi tích vô hướng giữa các điểm dữ liệu.

\textbf{Dự báo}
Giá trị bias $b$ được ước lượng bởi:
$
b = \frac{1}{N_M}
\left(
t_M - K_{MS}[\alpha_S \odot t_S]
\right)^T \mathbf{1}
$

Hàm dự báo:
$
y = K_{BS}[\alpha_S \odot t_S] + b
$

Nhãn dự đoán:
$
\text{label} = \text{sign}(y)
$

\textbf{Khi đường biên giới phi tuyến}
Trong nhiều bài toán thực tế, dữ liệu không thể phân tách tuyến tính.
Giải pháp là ánh xạ dữ liệu thông qua hàm trích đặc trưng:
$
\Phi: \mathbb{R}^d \rightarrow \mathcal{H}
$

Tuy nhiên, việc tính trực tiếp $\Phi(x)$ có thể tốn kém hoặc không khả thi
khi không gian đặc trưng có số chiều rất lớn hoặc vô hạn.

\textbf{Phương pháp Kernel}
Phương pháp kernel cho phép tính:
$
\langle \Phi(x_i), \Phi(x_j) \rangle
$
mà không cần biết tường minh $\Phi(x)$, thông qua một hàm kernel:
$
k(x_i,x_j)
$

\textbf{Điều kiện Mercer}
Một hàm $k(x_i,x_j)$ là kernel hợp lệ nếu:
\begin{itemize}
\item Đối xứng: $k(x_i,x_j) = k(x_j,x_i)$
\item Bán định dương:
$
\sum_{i=1}^N \sum_{j=1}^N c_i c_j k(x_i,x_j) \ge 0
$
\end{itemize}

\textbf{Huấn luyện và dự báo với Kernel}
Ma trận Gram kernel:
$
K_{Gram} =
\begin{bmatrix}
k(x_1,x_1) & \cdots & k(x_1,x_N)\\
\vdots & \ddots & \vdots\\
k(x_N,x_1) & \cdots & k(x_N,x_N)
\end{bmatrix}
$

Việc sử dụng kernel đảm bảo bài toán tối ưu là lồi và có nghiệm toàn cục.

\textbf{Các kernel thông dụng}
Một số kernel phổ biến trong thực tế:

\begin{itemize}
\item \textbf{Linear}:
$
k(x,x') = x^T x'
$

\item \textbf{Polynomial}:
$
k(x,x') = (\gamma x^T x' + r)^d
$

\item \textbf{RBF (Gaussian)}:
$
k(x,x') = \exp(-\gamma \|x-x'\|^2)
$

\item \textbf{Sigmoid}:
$
k(x,x') = \tanh(\gamma x^T x' + r)
$
\end{itemize}

Kernel RBF tương ứng với không gian đặc trưng vô hạn chiều.

\textbf{Thiết kế Kernel}
Việc thiết kế kernel phụ thuộc mạnh vào kiến thức miền (domain knowledge),
với mục tiêu:
\begin{itemize}
\item $k(x_i,x_j)$ lớn nếu $x_i, x_j$ cùng lớp
\item $k(x_i,x_j)$ nhỏ nếu khác lớp
\end{itemize}

\textbf{Minh họa}
Các thí nghiệm với kernel đa thức và kernel RBF cho thấy khả năng
phi tuyến hóa đường biên phân lớp một cách hiệu quả.


% SECTION 10 : PCA


\section{PCA}

\textbf{Mô tả bài toán}
Giả sử tập dữ liệu đầu vào:
$
X =
\begin{bmatrix}
x_{1,1} & x_{1,2} & \cdots & x_{1,D} \\
x_{2,1} & x_{2,2} & \cdots & x_{2,D} \\
\vdots  & \vdots  & \ddots & \vdots  \\
x_{N,1} & x_{N,2} & \cdots & x_{N,D}
\end{bmatrix}
$
trong đó:
\begin{itemize}
    \item $X \in \mathbb{R}^{N \times D}$;
    \item $D$ rất lớn và các chiều có tương quan với nhau.
\end{itemize}

\textbf{Mục tiêu:}
\begin{enumerate}
    \item Giảm số chiều từ $D$ xuống $M$ với $M \ll D$;
    \item Các đặc trưng mới không còn tương quan tuyến tính.
\end{enumerate}

\textbf{Kiến thức toán học liên quan}
\textbf{Phương sai và hiệp phương sai}
Trung bình của dữ liệu:
$
\mu = \frac{1}{N}\sum_{n=1}^{N} x_n
$

Dữ liệu được chuẩn hóa:
$
z_n = x_n - \mu
$

Ma trận hiệp phương sai:
$
S = \frac{1}{N}\sum_{n=1}^{N}(x_n - \mu)(x_n - \mu)^T
$

\textbf{Eigenvalue và Eigenvector}
Với ma trận vuông $A$, bài toán eigen:
$
Au = \lambda u
$
trong đó $u$ là eigenvector và $\lambda$ là eigenvalue.

\textbf{Cơ sở lý luận của PCA}
PCA có thể được nhìn theo hai cách:
\begin{itemize}
    \item Cực đại hóa phương sai của dữ liệu sau khi chiếu;
    \item Cực tiểu hóa sai số phục hồi dữ liệu.
\end{itemize}

Hai cách tiếp cận này là tương đương về mặt toán học.

\textbf{Cực đại hóa phương sai}
Với một vectơ đơn vị $u$, phương sai của dữ liệu khi chiếu lên $u$ là:
$
\sigma^2 = u^T S u
$

Bài toán tối ưu:
$
\max_{u} \quad u^T S u
\quad \text{s.t.} \quad u^T u = 1
$

Sử dụng nhân tử Lagrange dẫn đến:
$
Su = \lambda u
$

Do đó:
\begin{itemize}
    \item Các trục chính của PCA là các eigenvector của $S$;
    \item Phương sai tương ứng là các eigenvalue.
\end{itemize}

\textbf{Thu giảm số chiều}
Chọn $M$ eigenvector tương ứng với $M$ eigenvalue lớn nhất, tạo thành ma trận:
$
\hat{U} = [u_1, u_2, \dots, u_M]
$

Chiếu dữ liệu:
$
X_{\text{PCA}} = (X - \mu^T)\hat{U}
$

Phục hồi xấp xỉ:
$
\hat{X} = \mu^T + X_{\text{PCA}}\hat{U}^T
$

\textbf{PCA qua API}
Ví dụ PCA trong \texttt{scikit-learn}:
\begin{verbatim}
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
pca.fit(X)
print(pca.explained_variance_ratio_)
\end{verbatim}

\textbf{Singular Value Decomposition (SVD)}
Phân rã SVD:
$
X = U S V^T
$

\begin{itemize}
    \item PCA thực hiện eigen-decomposition trên ma trận hiệp phương sai;
    \item SVD phân rã trực tiếp trên ma trận dữ liệu và có độ ổn định số cao hơn.
\end{itemize}

\textbf{Ứng dụng của PCA}
\begin{itemize}
    \item Nén dữ liệu;
    \item Trực quan hóa dữ liệu nhiều chiều;
    \item Tiền xử lý cho học máy;
    \item Nhận dạng mẫu và xử lý ảnh.
\end{itemize}


% SECTION 11: LDA
% ==========================================================
\section{LDA}

\textbf{Giới thiệu về LDA}


\textbf{Đầu vào}

Cho tập dữ liệu:
$
X =
\begin{bmatrix}
x_{1,1} & x_{1,2} & \cdots & x_{1,D} \\
x_{2,1} & x_{2,2} & \cdots & x_{2,D} \\
\vdots  & \vdots  & \ddots & \vdots  \\
x_{N,1} & x_{N,2} & \cdots & x_{N,D}
\end{bmatrix},
\quad
t =
\begin{bmatrix}
t_1 \\ t_2 \\ \vdots \\ t_N
\end{bmatrix}
$

Trong đó:
\begin{itemize}
  \item $X \in \mathbb{R}^{N \times D}$, với $D$ thường rất lớn.
  \item $t_k \in \{1,2,\ldots,C\}$ là nhãn lớp của điểm dữ liệu thứ $k$.
\end{itemize}

\textbf{Mục tiêu}

Mục tiêu của LDA là:
\begin{enumerate}
  \item Giảm số chiều từ $D$ xuống $M$, với $M \le C - 1$.
  \item Dữ liệu sau khi chiếu có độ phân tách giữa các lớp là lớn nhất.
\end{enumerate}

% ==========================================================
\textbf{LDA qua API}

Ví dụ sử dụng \texttt{Scikit-learn}:

\begin{verbatim}
from sklearn import datasets
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

iris = datasets.load_iris()
X = iris.data
y = iris.target

lda = LinearDiscriminantAnalysis(n_components=2)
X_r = lda.fit(X, y).transform(X)
\end{verbatim}

% ==========================================================
\textbf{Bài toán tối ưu}

\textbf{Tâm của mỗi lớp}

Với lớp $k$:
$
\mathbf{m}_k = \frac{1}{N_k} \sum_{n \in C_k} \mathbf{x}_n
$

\textbf{Between-class scatter matrix}

$
S_B = (\mathbf{m}_2 - \mathbf{m}_1)(\mathbf{m}_2 - \mathbf{m}_1)^T
$

\textbf{Within-class scatter matrix}

$
S_W = \sum_{k=1}^{C} \sum_{n \in C_k}
(\mathbf{x}_n - \mathbf{m}_k)(\mathbf{x}_n - \mathbf{m}_k)^T
$

\textbf{Hàm mục tiêu của Fisher}

$
J(\mathbf{w}) =
\frac{\mathbf{w}^T S_B \mathbf{w}}
     {\mathbf{w}^T S_W \mathbf{w}}
$

Mục tiêu:
$
\mathbf{w}^* = \arg\max_{\mathbf{w}} J(\mathbf{w})
$

% ==========================================================
\textbf{Tìm nghiệm}

Giải bài toán tối ưu dẫn đến phương trình trị riêng:
$
S_W^{-1} S_B \mathbf{w} = \lambda \mathbf{w}
$

Hướng chiếu tối ưu là:
$
\mathbf{w} \propto S_W^{-1}(\mathbf{m}_2 - \mathbf{m}_1)
$

% ==========================================================
\textbf{Trường hợp có $C$ lớp}

\textbf{Hàm mục tiêu tổng quát}

$
J(W) =
\frac{\text{trace}(W^T S_B W)}
     {\text{trace}(W^T S_W W)}
$

\textbf{Số chiều tối đa}

Số chiều tối đa có thể chọn là:
$
M \le C - 1
$

Do ma trận $S_B$ có hạng tối đa là $C-1$.

\textbf{Giải thuật LDA}

\begin{enumerate}
  \item Tính $S_B$ và $S_W$.
  \item Tính $A = S_W^{-1} S_B$.
  \item Thực hiện SVD hoặc eigen-decomposition.
  \item Chọn $M$ eigenvector tương ứng với eigenvalue lớn nhất.
  \item Chiếu dữ liệu: $\hat{X} = (X - m^T)W$.
\end{enumerate}

% ==========================================================

% SECTION 12: ENSEMBLE 

% --------------------
\section{Ensemble}

\textbf{Bias--Variance Perspective}

Prediction error can be decomposed into bias and variance. Bias results from
overly simplistic assumptions, while variance reflects sensitivity to training
data fluctuations. Ensemble learning aims to reduce variance by averaging
predictions of multiple weakly correlated models. For regression, the variance
of an ensemble predictor can be approximated as
$
\mathrm{Var}\left(
\frac{1}{M} \sum_{m=1}^{M} \hat{y}^{(m)}
\right)
\approx
\frac{1}{M^2} \sum_{m=1}^{M} \mathrm{Var}(\hat{y}^{(m)}).
$

% --------------------
\textbf{Bagging (Bootstrap Aggregating)}

Bagging is designed to reduce variance, particularly for unstable learners such
as decision trees.

\textbf{Method Description}

Given a training dataset
$
D = \{(x_i, y_i)\}_{i=1}^{n},
$
Bagging constructs an ensemble of $M$ models as follows:
\begin{enumerate}[label=\arabic*.]
\item Draw $M$ bootstrap datasets $D_1, D_2, \dots, D_M$ by sampling $n$ points
with replacement from $D$.
\item Train a base learner on each bootstrap dataset to obtain models
$h_1, h_2, \dots, h_M$.
\item Combine predictions of all models:
$
\hat{y}(x) =
\begin{cases}
\frac{1}{M}\sum_{m=1}^{M} h_m(x), & \text{regression}, \\
\text{majority vote}, & \text{classification}.
\end{cases}
$
\end{enumerate}

\textbf{Properties}

Bagging is simple, highly parallelizable, and effective at variance reduction.
However, it requires storing many models and results in slower inference.

% --------------------
\textbf{Random Forest}

Random Forest extends Bagging by introducing randomness in feature selection.
Each tree is trained on a bootstrap dataset, and at each split only a random
subset of features is considered.

\textbf{Training Procedure}

For each tree:
\begin{enumerate}[label=\arabic*.]
\item Sample a bootstrap dataset from the training set.
\item Grow a decision tree by recursively splitting nodes.
\item At each split, randomly select a subset of features
$F_{\text{sub}} \subset \{1,\dots,d\}$.
\item Choose the best split using only features in $F_{\text{sub}}$.
\end{enumerate}

Typical choices are $|F_{\text{sub}}|=\sqrt{d}$ for classification and
$|F_{\text{sub}}|=d/3$ for regression.

% --------------------
\textbf{Boosting}

Boosting methods train models sequentially, where each model focuses on samples
misclassified by previous ones. Unlike Bagging, Boosting can reduce both bias
and variance.

\textbf{AdaBoost}

For binary classification with $y_i \in \{-1,+1\}$, AdaBoost maintains a weight
distribution over training samples. At iteration $t$, a weak learner $h_t$ is
trained using weighted data. The final classifier is
$
H(x) = \mathrm{sign}
\left(
\sum_{t=1}^{T} \alpha_t h_t(x)
\right),
$
where $\alpha_t$ is determined by the weighted classification error of $h_t$.

\textbf{Gradient Boosting}

Gradient Boosting views ensemble construction as gradient descent in function
space. At each iteration, a new weak learner is fitted to the negative gradient
of the loss function with respect to current predictions.

% --------------------
\textbf{Voting and Stacking}

\textbf{Voting}

Voting combines predictions of multiple models using a fixed rule such as
majority voting or probability averaging. It is simple and often serves as a
strong baseline.

\textbf{Stacking}

Stacking trains a meta-learner on predictions of base models. To avoid
overfitting, cross-validation is used to generate out-of-fold predictions, which
are then used as inputs for the meta-model.

% --------------------
\textbf{Comparison and Practical Considerations}

Bagging is most effective for high-variance models, Boosting can significantly
improve accuracy but is sensitive to noise, and Stacking offers the greatest
flexibility at the cost of increased complexity. In practice, Random Forests
and Gradient Boosting are strong default choices for tabular data.

% --------------------

% SECTION 13: GENETIC ALGORITHM

\section{Genetic algorithm}

\textbf{Key Components of Genetic Algorithms}

\textbf{Representation (Encoding)}

A solution is encoded as a chromosome. Common encoding methods include:
\begin{itemize}
    \item \textbf{Binary encoding}: chromosomes consist of bits (0 or 1)
    \item \textbf{Real-valued encoding}: genes are real numbers
    \item \textbf{Permutation encoding}: chromosomes represent ordered sequences
    \item \textbf{Tree encoding}: solutions are tree structures (used in genetic programming)
\end{itemize}

\textbf{Fitness Function}

The fitness function $f(x)$ evaluates the quality of a solution $x$.
For minimization problems, a transformation is typically applied, such as:
$
f_{\text{max}}(x) = \frac{1}{1 + f_{\text{min}}(x)}
$

The fitness function should be computationally efficient, as it is evaluated
many times during the evolutionary process.

\textbf{Selection}

Selection chooses parent solutions based on fitness.
Popular methods include:
\begin{itemize}
    \item Roulette wheel selection
    \item Rank selection
    \item Tournament selection
    \item Elitism
\end{itemize}

Elitism ensures that the best individuals are preserved across generations.

\textbf{Crossover}

Crossover combines genetic material from two parents to produce offspring.
Common techniques include:
\begin{itemize}
    \item Single-point crossover
    \item Two-point crossover
    \item Uniform crossover
    \item Arithmetic crossover (for real-valued encoding)
\end{itemize}

\textbf{Mutation}

Mutation introduces random changes to maintain population diversity.
Typical mutation strategies include:
\begin{itemize}
    \item Bit flipping for binary encoding
    \item Gaussian or uniform noise for real-valued encoding
    \item Swap or inversion for permutation encoding
\end{itemize}

\textbf{Genetic Algorithm Framework}

A standard genetic algorithm follows these steps:
\begin{enumerate}
    \item Initialize a population of $N$ individuals
    \item Evaluate fitness of each individual
    \item Repeat until a termination condition is met:
    \begin{enumerate}
        \item Select parents based on fitness
        \item Apply crossover to generate offspring
        \item Apply mutation to offspring
        \item Evaluate fitness of new individuals
        \item Form the next generation (with optional elitism)
    \end{enumerate}
    \item Return the best solution found
\end{enumerate}

Termination conditions may include a maximum number of generations,
fitness convergence, stagnation, or time limits.

\textbf{Simple Example}

Consider maximizing the function:
$
f(x) = x^2, \quad x \in \{0,1,\ldots,15\}
$

Binary encoding with 4 bits is used.
An example initial population is shown in Table~\ref{tab:initpop}.

\begin{table}[h]
\centering
\caption{Initial population}
\label{tab:initpop}
\begin{tabular}{cccc}
\toprule
Individual & Binary & $x$ & $f(x)$ \\
\midrule
A & 0110 & 6 & 36 \\
B & 1001 & 9 & 81 \\
C & 0011 & 3 & 9 \\
D & 1100 & 12 & 144 \\
\bottomrule
\end{tabular}
\end{table}

After selection, crossover, and mutation, the population gradually
converges toward the optimal solution $x=15$.

\textbf{Parameters and Tuning}

Key parameters include:
\begin{itemize}
    \item Population size ($N$)
    \item Crossover probability ($p_c$)
    \item Mutation probability ($p_m$)
\end{itemize}

Typical values are:
\begin{itemize}
    \item $N = 20$--$200$
    \item $p_c = 0.6$--$0.9$
    \item $p_m = 0.001$--$0.1$
\end{itemize}

Parameter selection is problem-dependent and often requires empirical tuning.

\textbf{Advantages and Disadvantages}

\textbf{Advantages}
\begin{itemize}
    \item Global search capability
    \item No requirement for gradient information
    \item Parallelizable structure
    \item Flexible solution representation
\end{itemize}

\textbf{Disadvantages}
\begin{itemize}
    \item No guarantee of global optimality
    \item Computationally expensive
    \item Sensitive to parameter settings
    \item Risk of premature convergence
\end{itemize}

\textbf{Applications}

Genetic Algorithms have been successfully applied in:
\begin{itemize}
    \item Combinatorial optimization (TSP, scheduling)
    \item Machine learning (feature selection, hyperparameter tuning)
    \item Engineering design (antennas, circuits)
    \item Bioinformatics (protein structure prediction)
    \item Game AI and procedural content generation
\end{itemize}

\textbf{Variants and Extensions}

Popular GA variants include:
\begin{itemize}
    \item Real-Coded Genetic Algorithms (RCGA)
    \item Differential Evolution (DE)
    \item Genetic Programming (GP)
    \item Multi-objective Genetic Algorithms (e.g., NSGA-II)
\end{itemize}

These variants extend GA to continuous, programmatic,
and multi-objective optimization problems.


\end{multicols}

% ==================================================
\end{document}
