\documentclass[10pt,a4paper]{article}

% ---------------- Packages ----------------
\usepackage[utf8]{inputenc}
\usepackage[T5]{fontenc}
\usepackage[vietnamese]{babel}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{enumitem}

\usepackage{multicol}

\geometry{margin=0.5cm}
\setlength{\parindent}{0pt}

% ---------------- Title ----------------


\begin{document}

\begin{multicols}{3}

% SECTION 1: LINEAR REGRESSION

\section{Định nghĩa bài toán}

\subsection{Đầu vào}

Cho tập dữ liệu gồm $N$ mẫu:
\begin{itemize}
    \item Tập các vector đặc trưng:
    \[
        \mathbf{x}_n = [x_{n,0}, x_{n,1}, \dots, x_{n,D-1}]^T,
        \quad n = 1, \dots, N
    \]
    với $x_{n,0} = 1$.
    
    \item Vector nhãn:
    \[
        \mathbf{t} = [t_1, t_2, \dots, t_N]^T
    \]
\end{itemize}

Dữ liệu được tổ chức dưới dạng:
\[
\mathbf{X} =
\begin{bmatrix}
1 & x_{1,1} & \dots & x_{1,D-1} \\
1 & x_{2,1} & \dots & x_{2,D-1} \\
\vdots & \vdots & \ddots & \vdots \\
1 & x_{N,1} & \dots & x_{N,D-1}
\end{bmatrix},
\quad
\mathbf{t} =
\begin{bmatrix}
t_1 \\ t_2 \\ \vdots \\ t_N
\end{bmatrix}
\]

\subsection{Giả thiết}

Giả sử nhãn được sinh theo mô hình:
\begin{equation}
t = h(\mathbf{x}) + \varepsilon
\end{equation}

Trong đó:
\begin{itemize}
    \item $h(\mathbf{x})$: hàm hồi quy tối ưu (chưa biết)
    \item $\varepsilon \sim \mathcal{N}(0, \sigma^2)$: nhiễu Gauss
\end{itemize}

Các mẫu dữ liệu và nhiễu được giả thiết là \textit{i.i.d}.

\subsection{Đầu ra}

Mô hình hồi quy tuyến tính:
\begin{equation}
\hat{y}(\mathbf{x}, \mathbf{w}) = \mathbf{w}^T \mathbf{x}
\end{equation}

với:
\[
\mathbf{w} = [w_0, w_1, \dots, w_{D-1}]^T
\]

% =====================================================
\section{Giải bài toán}

\subsection{Nguyên tắc chung}

Bài toán được giải bằng cách:
\begin{itemize}
    \item Xây dựng hàm hợp lý
    \item Cực đại hóa hợp lý (Maximum Likelihood)
\end{itemize}

\subsection{Hợp lý cực đại}

Với giả thiết nhiễu Gauss:
\begin{equation}
p(t_n | \mathbf{x}_n, \mathbf{w}, \beta)
= \mathcal{N}(t_n | \mathbf{w}^T \mathbf{x}_n, \beta^{-1})
\end{equation}

Hàm negative log-likelihood:
\begin{equation}
L(\mathbf{w}, \beta)
= \beta E_D(\mathbf{w})
- \frac{N}{2} \log \beta
+ \frac{N}{2} \log(2\pi)
\end{equation}

với:
\begin{equation}
E_D(\mathbf{w})
= \frac{1}{2}\sum_{n=1}^N (t_n - \mathbf{w}^T \mathbf{x}_n)^2
\end{equation}

\subsection{Nghiệm giải tích}

Cực tiểu $E_D(\mathbf{w})$ cho nghiệm:
\begin{equation}
\mathbf{w}_{ML} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{t}
\end{equation}

Ước lượng phương sai nhiễu:
\begin{equation}
\beta_{ML}^{-1}
= \frac{1}{N}\sum_{n=1}^N
(t_n - \mathbf{w}_{ML}^T\mathbf{x}_n)^2
\end{equation}

\subsection{Giải thuật lặp (Gradient Descent)}

Cập nhật tham số:
\begin{equation}
\mathbf{w}^{(t)}
= \mathbf{w}^{(t-1)} - \eta \nabla E_D(\mathbf{w})
\end{equation}

% =====================================================
\section{Hồi quy cho quan hệ phi tuyến}

Ánh xạ dữ liệu sang không gian đặc trưng mới:
\[
\mathbf{x} \rightarrow
\boldsymbol{\phi}(\mathbf{x})
= [\phi_0(\mathbf{x}), \dots, \phi_{M-1}(\mathbf{x})]
\]

Sau đó áp dụng hồi quy tuyến tính trên không gian mới.

% =====================================================
\section{Đánh giá mô hình}

\subsection{Dự báo}

\begin{equation}
\hat{\mathbf{y}} = \mathbf{X}\mathbf{w}_{ML}
\end{equation}

\subsection{Các độ đo}

Mean Squared Error:
\begin{equation}
\mathrm{MSE}
= \frac{1}{N}\sum_{n=1}^N (t_n - \hat{y}_n)^2
\end{equation}

Root Mean Squared Error:
\begin{equation}
\mathrm{RMSE} = \sqrt{\mathrm{MSE}}
\end{equation}

% =====================================================
\section{Hạn chế quá khớp}

\subsection{Ridge Regression}

\begin{equation}
L(\mathbf{w})
= \frac{1}{2}\sum_{n=1}^N (t_n - \mathbf{w}^T\mathbf{x}_n)^2
+ \frac{\lambda}{2}\mathbf{w}^T\mathbf{w}
\end{equation}

Nghiệm:
\begin{equation}
\mathbf{w}_{ridge}
= (\lambda \mathbf{I} + \mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{t}
\end{equation}

\subsection{LASSO}

\begin{equation}
L(\mathbf{w})
= \frac{1}{2}\sum_{n=1}^N (t_n - \mathbf{w}^T\mathbf{x}_n)^2
+ \lambda \sum_{m=1}^M |w_m|
\end{equation}

% =====================================================
\section{Dự báo cho nhiều biến}

Với $K$ biến đầu ra:
\begin{equation}
\mathbf{W}
= (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{T}
\end{equation}

Trong đó:
\begin{itemize}
    \item $\mathbf{T} \in \mathbb{R}^{N \times K}$
    \item $\mathbf{W} \in \mathbb{R}^{M \times K}$
\end{itemize}

% SECTION 2: LOGISTIC REGRESSION
% ==================================================
\section{Giới thiệu bài toán}

% --------------------------------------------------
\subsection{Đầu vào}

\subsubsection{Dữ liệu đầu vào}

Ma trận dữ liệu:
\[
X =
\begin{bmatrix}
1 & x_{1,1} & x_{1,2} & \cdots & x_{1,(M-1)} \\
1 & x_{2,1} & x_{2,2} & \cdots & x_{2,(M-1)} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_{N,1} & x_{N,2} & \cdots & x_{N,(M-1)}
\end{bmatrix}
\]

\begin{itemize}
    \item Mỗi hàng tương ứng với một điểm dữ liệu
    \item $X$ có kích thước $N \times M$
\end{itemize}

\subsubsection{Tập nhãn}

\begin{itemize}
    \item Bài toán có hai nhãn
    \item Mỗi nhãn được mã hóa bằng chỉ số $\{0,1\}$
\end{itemize}

\subsubsection{Nhãn dữ liệu}

\[
t = (t_1, t_2, \ldots, t_N)^T
\]

\subsubsection{Quy ước}

\begin{itemize}
    \item $X$: ma trận dữ liệu, kích thước $N \times M$
    \item $t$: vector nhãn
    \item $y$: biểu diễn dạng số của nhãn
    \item $N$: số điểm dữ liệu
    \item $M$: số đặc trưng
    \item $\hat{y}$: giá trị dự báo từ mô hình
\end{itemize}

% ==================================================
\section{Phương pháp xây dựng mô hình}

\subsection{Ý tưởng}

\begin{itemize}
    \item Hai lớp: $C_0$ và $C_1$
    \item Mô hình dự báo xác suất $x$ thuộc lớp $C_1$
    \item Xác suất thuộc lớp $C_0$ là $1 - \hat{y}$
\end{itemize}

Bên trong mô hình:
\begin{enumerate}
    \item Sử dụng mô hình tuyến tính:
    \[
    z = w^T x
    \]
    \item Đưa $z$ qua hàm sigmoid
\end{enumerate}

\subsection{Hàm sigmoid}

\[
\sigma(z) = \frac{1}{1 + e^{-z}}
\]

\subsection{Mô hình dự báo}

\begin{equation}
\hat{y} = p(C_1|x,w) = \sigma(w^T x)
\label{eq:logistic}
\end{equation}

Quy tắc phân lớp:
\begin{itemize}
    \item Nếu $\hat{y} \ge \lambda$ thì $x \in C_1$
    \item Ngược lại, $x \in C_0$
\end{itemize}

% ==================================================
\section{Ước lượng tham số của mô hình}

\subsection{Xây dựng hàm mục tiêu}

Với một điểm dữ liệu $(x,y)$:
\[
p(y|x,w) =
\hat{y}^y (1-\hat{y})^{1-y}
\]

Với $N$ điểm dữ liệu:
\[
p(t|X,w) = \prod_{n=1}^{N} \hat{y}_n^{y_n} (1-\hat{y}_n)^{1-y_n}
\]

Sử dụng \textbf{negative log-likelihood}:
\begin{equation}
L(w) = -\sum_{n=1}^{N}
\left[
y_n \log \hat{y}_n + (1-y_n)\log(1-\hat{y}_n)
\right]
\label{eq:loss}
\end{equation}

Hàm này còn được gọi là \textbf{cross-entropy}.

\subsection{Tìm hệ số của mô hình}

Gradient của hàm mất mát:
\begin{equation}
\nabla L(w) = \sum_{n=1}^{N} (\hat{y}_n - y_n)x_n
= X^T(\hat{y} - y)
\end{equation}

\subsection{Giải thuật lặp với đạo hàm bậc 2}

Ma trận Hessian:
\begin{equation}
H = \nabla^2 L(w)
= \sum_{n=1}^{N} \hat{y}_n(1-\hat{y}_n)x_n x_n^T
= X^T R X
\end{equation}

Trong đó $R$ là ma trận đường chéo:
\[
R_{nn} = \hat{y}_n(1-\hat{y}_n)
\]

Phương pháp sử dụng:
\begin{itemize}
    \item Gradient Descent
    \item Newton--Raphson
    \item Iterative Re-weighted Least Squares (IRLS)
\end{itemize}

% SECTION 3: SOFTMAX REGRESSION


% ==================================================
\section{Dữ liệu đầu vào}

\subsection{Ma trận dữ liệu}

Giả sử tập dữ liệu đầu vào được biểu diễn bởi ma trận:
\[
X =
\begin{bmatrix}
1 & x_{1,1} & x_{1,2} & \cdots & x_{1,(M-1)} \\
1 & x_{2,1} & x_{2,2} & \cdots & x_{2,(M-1)} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_{N,1} & x_{N,2} & \cdots & x_{N,(M-1)}
\end{bmatrix}
\]
trong đó $X \in \mathbb{R}^{N \times M}$.

\subsection{Nhãn và biểu diễn one-hot}

Mỗi nhãn được mã hóa dưới dạng véctơ one-hot kích thước $K$.
Ví dụ với $K=4$:

\begin{center}
\begin{tabular}{ccc}
\toprule
Nhãn & Chỉ số & One-hot \\
\midrule
Chó   & 0 & [1, 0, 0, 0] \\
Mèo  & 1 & [0, 1, 0, 0] \\
Chuột& 2 & [0, 0, 1, 0] \\
Thỏ  & 3 & [0, 0, 0, 1] \\
\bottomrule
\end{tabular}
\end{center}

% ==================================================
\section{Mô hình tuyến tính với Softmax}

\subsection{Mô hình dự báo}

Ma trận tham số của mô hình:
\[
W =
\begin{bmatrix}
w_1^T \\
w_2^T \\
\vdots \\
w_K^T
\end{bmatrix}
\in \mathbb{R}^{K \times M}
\]

Các bước tính toán:
\begin{align}
Z &= XW^T \quad (N \times K) \\
\hat{Y} &= \text{softmax}(Z)
\end{align}

Hàm softmax được định nghĩa:
\[
\hat{y}_k = \frac{\exp(z_k)}{\sum_{i=1}^{K} \exp(z_i)}
\]

\subsection{Dự đoán}

Nhãn dự đoán của mẫu dữ liệu được xác định bằng:
\[
\text{prediction} = \arg\max_k \hat{y}_k
\]

% ==================================================
\section{Hàm mục tiêu và tối ưu}

\subsection{Hàm hợp lý}

Xác suất của tập nhãn:
\[
p(t|X,W) = \prod_{n=1}^{N} \prod_{k=1}^{K} \hat{y}_{n,k}^{y_{n,k}}
\]

\subsection{Hàm mất mát Cross-Entropy}

Hàm mất mát được xây dựng bằng cách lấy log và đổi dấu:
\[
L(W) = -\sum_{n=1}^{N}\sum_{k=1}^{K} y_{n,k}\log(\hat{y}_{n,k})
\]

Mục tiêu là tìm $W$ sao cho $L(W)$ đạt giá trị nhỏ nhất.

% ==================================================
\section{Ước lượng tham số}

\subsection{Gradient Descent}

Gradient của hàm mất mát đối với đầu vào softmax:
\[
\frac{\partial L}{\partial z} = (\hat{y} - y)^T
\]

Gradient theo tham số:
\[
\Delta W = (\hat{y} - y)^T x^T
\]

Cập nhật trọng số:
\[
W \leftarrow W - \eta \Delta W
\]
trong đó $\eta$ là hệ số học.

% ==================================================
\section{Mở rộng cho đường biên phi tuyến}

Để xử lý dữ liệu không phân tách tuyến tính, có thể:
\begin{itemize}
\item Biến đổi đặc trưng sang không gian mới
\item Sử dụng hàm cơ sở đa thức
\item Áp dụng mạng nơ-ron để học đặc trưng
\end{itemize}

% ==================================================



% SECTION 4: MLP
% ======================================================
\section{MLP: Computational Architecture View}

An MLP consists of:
\begin{itemize}
    \item A \textbf{feature transformer}: stacked linear layers with nonlinear activations.
    \item An \textbf{output head}:
    \begin{itemize}
        \item Linear head for regression
        \item Logistic or softmax head for classification
    \end{itemize}
\end{itemize}

\textbf{Core idea:}
deep learning = nonlinear feature extraction + simple linear head.

% ======================================================
\section{MLP: Mathematical Model}

\subsection{Forward Pass}

Let $h^{(0)} = x$. Each hidden layer computes:
\begin{equation}
h^{(l)} = \phi\left(W^{(l)}h^{(l-1)} + b^{(l)}\right),
\quad l = 1,\dots,L
\end{equation}

where $\phi(\cdot)$ is a nonlinear activation function.

\subsection{Output Layer}

\textbf{Regression:}
\begin{equation}
\hat{y} = W^{(L+1)}h^{(L)} + b^{(L+1)}
\end{equation}

\textbf{Classification (Softmax):}
\begin{equation}
\hat{p}_k =
\frac{\exp(w_k^\top h^{(L)} + b_k)}
{\sum_{j}\exp(w_j^\top h^{(L)} + b_j)}
\end{equation}

\subsection{Function Composition View}

An MLP is a composition of functions:
\begin{equation}
f(x;\theta) =
f^{(L+1)} \circ \phi \circ f^{(L)} \circ \cdots \circ \phi \circ f^{(1)}(x)
\end{equation}

More layers imply higher representation power.

% ======================================================
\section{MLP: Layers}

\subsection{Fully Connected (Linear) Layer}

For a single sample:
\begin{equation}
y = Wx + b
\end{equation}

For a mini-batch $X \in \mathbb{R}^{B \times N}$:
\begin{equation}
Y = XW^\top + \mathbf{1}b^\top
\end{equation}

\subsection{Activation Functions}

\paragraph{Sigmoid}
\begin{equation}
\sigma(z)=\frac{1}{1+e^{-z}}
\end{equation}

\paragraph{Tanh}
\begin{equation}
\tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}
\end{equation}

\paragraph{ReLU}
\begin{equation}
\mathrm{ReLU}(z)=\max(0,z)
\end{equation}

\paragraph{Leaky ReLU}
\begin{equation}
\mathrm{LReLU}(z)=
\begin{cases}
z, & z\ge 0\\
\alpha z, & z<0
\end{cases}
\end{equation}

\paragraph{SiLU (Swish)}
\begin{equation}
\mathrm{SiLU}(z)=z\sigma(z)
\end{equation}


% SECTION 5: SVM PRIMAL PROBLEM
\section{Giới thiệu bài toán}

\subsection{Đầu vào}

Dữ liệu huấn luyện gồm:
\begin{itemize}
    \item Ma trận dữ liệu:
    \[
    X =
    \begin{bmatrix}
    x_{1,1} & x_{1,2} & \cdots & x_{1,(M-1)} \\
    x_{2,1} & x_{2,2} & \cdots & x_{2,(M-1)} \\
    \vdots  & \vdots  & \ddots & \vdots \\
    x_{N,1} & x_{N,2} & \cdots & x_{N,(M-1)}
    \end{bmatrix}
    \]
    với $X \in \mathbb{R}^{N \times (M-1)}$.
    
    \item Véc-tơ nhãn:
    \[
    \mathbf{t} =
    \begin{bmatrix}
    t_1 \\ t_2 \\ \vdots \\ t_N
    \end{bmatrix}, \quad t_n \in \{-1, +1\}
    \]
\end{itemize}

\subsection{Giả thiết}

Dữ liệu thuộc hai lớp có thể \textbf{phân tách tuyến tính}, tức tồn tại một siêu phẳng sao cho các điểm mang nhãn $+1$ và $-1$ nằm ở hai phía khác nhau.

\subsection{Mục tiêu}

Xác định đường biên quyết định:
\[
\mathbf{w}^T \mathbf{x} + b = 0
\]
sao cho \textbf{lề (margin)} giữa hai lớp là lớn nhất.

\subsection{SVM với \texttt{scikit-learn}}

Ví dụ sử dụng SVM trong \texttt{scikit-learn}:
\begin{verbatim}
from sklearn import svm
X = [[0, 0], [1, 1]]
y = [0, 1]
clf = svm.SVC()
clf.fit(X, y)
clf.predict([[2., 2.]])
\end{verbatim}

% =====================================================
\section{Phương pháp xây dựng bộ phân lớp}

\subsection{Nguyên tắc}

Quy trình gồm ba bước chính:
\begin{enumerate}
    \item Chuyển về bài toán tối ưu có ràng buộc với mục tiêu cực đại lề (bài toán gốc).
    \item Chuyển sang bài toán đối ngẫu (Dual problem).
    \item Giải bài toán tối ưu bằng các thư viện tối ưu lồi như \texttt{CVXOPT}.
\end{enumerate}

% =====================================================
\section{Bài toán gốc (Primal Problem)}

\subsection{Khoảng cách từ điểm đến đường thẳng}

Siêu phẳng trong không gian đặc trưng $(M-1)$ chiều:
\[
\mathbf{w}^T \mathbf{x} + b = 0
\]

Khoảng cách có dấu từ điểm $\mathbf{x}$ đến siêu phẳng:
\[
d(\mathbf{x}) = \frac{\mathbf{w}^T \mathbf{x} + b}{\|\mathbf{w}\|}
\]

Khoảng cách hình học:
\[
|d(\mathbf{x})| = \frac{|\mathbf{w}^T \mathbf{x} + b|}{\|\mathbf{w}\|}
\]

\subsection{Hàm quyết định}

Hàm quyết định:
\[
y(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b
\]

Quy tắc phân lớp:
\[
\text{class}(\mathbf{x}) = \text{sign}(y(\mathbf{x}))
\]

\subsection{Lề (Margin)}

Lề trên tập huấn luyện:
\[
m_{\mathbf{w}} = \min_{n} \frac{t_n(\mathbf{w}^T \mathbf{x}_n + b)}{\|\mathbf{w}\|}
\]

\subsection{Cực đại lề}

Có thể chuẩn hóa sao cho:
\[
t_n(\mathbf{w}^T \mathbf{x}_n + b) \ge 1, \quad \forall n
\]

\subsection{Hàm mục tiêu}

Cực đại lề tương đương với bài toán:
\[
\min_{\mathbf{w}, b} \frac{1}{2}\|\mathbf{w}\|^2
\]

với ràng buộc:
\[
t_n(\mathbf{w}^T \mathbf{x}_n + b) \ge 1, \quad n=1,\dots,N
\]

\subsection{Bài toán gốc}

\[
\begin{aligned}
\mathbf{w}^*, b^* = \arg\min_{\mathbf{w}, b} \quad &
\frac{1}{2}\|\mathbf{w}\|^2 \\
\text{s.t.} \quad &
t_n(\mathbf{w}^T \mathbf{x}_n + b) \ge 1,\quad \forall n
\end{aligned}
\]

\subsection{Giải bằng thư viện CVXOPT}

Dạng chuẩn:
\[
\min_{\mathbf{x}} \frac{1}{2}\mathbf{x}^T K \mathbf{x} + \mathbf{p}^T \mathbf{x}
\quad \text{s.t. } G\mathbf{x} \le \mathbf{h}
\]

Trong đó:
\[
\mathbf{x} =
\begin{bmatrix}
\mathbf{w} \\ b
\end{bmatrix}
\]


% SECTION 6: SVM DUAL PROBLEM

% =====================================================

% =====================================================
\section{Bài toán đối ngẫu}

\subsection{Hàm Lagrangian}

Hàm Lagrangian của bài toán \eqref{eq:primal} là:
\begin{equation}
L(w,b,\alpha)
=
\frac{1}{2}\|w\|^2
-
\sum_{n=1}^N \alpha_n
\bigl[t_n(w^T x_n + b) - 1\bigr],
\label{eq:lagrangian}
\end{equation}
với
\[
\alpha_n \ge 0,\quad n=1,\dots,N.
\]

\subsection{Điều kiện KKT}

Bài toán thỏa hệ điều kiện KKT:
\begin{itemize}
\item \textbf{(KKT-1)} Điều kiện dừng:
\[
\nabla_{w,b} L(w,b,\alpha)=0
\]
\item \textbf{(KKT-2)} Ràng buộc gốc
\item \textbf{(KKT-3)} Ràng buộc đối ngẫu: $\alpha_n \ge 0$
\item \textbf{(KKT-4)} Điều kiện bù:
\[
\alpha_n[1-t_n(w^Tx_n+b)]=0
\]
\end{itemize}

% =====================================================
\section{Xây dựng hàm đối ngẫu}

Lấy đạo hàm theo $w$ và $b$:
\begin{align}
\frac{\partial L}{\partial w} &= w - \sum_{n=1}^N \alpha_n t_n x_n = 0
\label{eq:w}\\
\frac{\partial L}{\partial b} &= \sum_{n=1}^N \alpha_n t_n = 0
\label{eq:b}
\end{align}

Suy ra:
\begin{equation}
w = \sum_{n=1}^N \alpha_n t_n x_n.
\end{equation}

Thay vào Lagrangian, ta thu được hàm đối ngẫu:
\begin{equation}
g(\alpha)
=
\sum_{n=1}^N \alpha_n
-
\frac{1}{2}
\sum_{r=1}^N \sum_{c=1}^N
\alpha_r \alpha_c t_r t_c x_r^T x_c.
\end{equation}

% =====================================================
\section{Bài toán đối ngẫu}

Bài toán đối ngẫu tương đương:
\begin{equation}
\begin{aligned}
\alpha^\ast
&= \arg\min_{\alpha}
\;\frac{1}{2}\alpha^T K \alpha - \mathbf{1}^T \alpha \\
\text{s.t.}\quad
& \alpha_n \ge 0,\quad n=1,\dots,N,\\
& \sum_{n=1}^N \alpha_n t_n = 0,
\end{aligned}
\label{eq:dual}
\end{equation}
trong đó
\[
K_{rc} = t_r t_c x_r^T x_c.
\]

% =====================================================
\section{Tiêu chuẩn Slater}

Vì tồn tại $(w,b)$ sao cho
\[
t_n(w^Tx_n+b) > 1,\;\forall n,
\]
nên bài toán thỏa tiêu chuẩn Slater.
Do đó:
\[
\min_{w,b} \max_{\alpha} L(w,b,\alpha)
=
\max_{\alpha} \min_{w,b} L(w,b,\alpha).
\]

Suy ra \textbf{duality gap bằng 0}.

% =====================================================
\section{Công thức dự báo}

Với tập véc-tơ hỗ trợ $S = \{n : \alpha_n > 0\}$,
\begin{equation}
y(x)
=
\sum_{n\in S} \alpha_n t_n x_n^T x + b.
\end{equation}

Nhãn dự báo:
\[
\hat{y} = \operatorname{sign}(y(x)).
\]



% SECTION 7: SVM SOFT MARGIN

%------------------------------------------------
\section{Giới thiệu bài toán không khả tách tuyến tính}

Trong thực tế, dữ liệu thường \textbf{không khả tách tuyến tính}.
Khi đó:
\begin{itemize}
    \item Tập nghiệm khả thi của hard-margin là rỗng.
    \item Không tồn tại $w,b$ thỏa tất cả các ràng buộc.
\end{itemize}

Do đó, cần mở rộng mô hình bằng cách cho phép một số điểm vi phạm ràng buộc.

%------------------------------------------------
\section{Nguyên tắc Soft Margin}

Ý tưởng chính:
\begin{enumerate}
    \item Nới lỏng ràng buộc bằng biến phạt $\xi_n$.
    \item Phạt các điểm nằm sai vị trí thông qua hàm mục tiêu.
\end{enumerate}

Mô hình này được gọi là \textbf{Soft Margin SVM}.

%------------------------------------------------
\section{Bài toán gốc với lề mềm}

\subsection{Ràng buộc mới}

\begin{align}
t_n(w^T x_n + b) &\ge 1 - \xi_n, \quad n=1,\dots,N, \\
\xi_n &\ge 0.
\end{align}

\subsection{Hàm mục tiêu mới}

\begin{equation}
f_0(w,b,\xi) =
\frac{1}{2}\|w\|^2 + C \sum_{n=1}^N \xi_n,
\end{equation}
trong đó $C > 0$ là siêu tham số điều chỉnh mức phạt.

\subsection{Bài toán tối ưu}

\begin{equation}
\begin{aligned}
\min_{w,b,\xi} \quad &
\frac{1}{2}\|w\|^2 + C \sum_{n=1}^N \xi_n \\
\text{s.t.} \quad &
t_n(w^T x_n + b) \ge 1 - \xi_n, \\
& \xi_n \ge 0,\quad n=1,\dots,N.
\end{aligned}
\end{equation}

%------------------------------------------------
\section{Bài toán đối ngẫu}

\subsection{Hàm Lagrangian}

\begin{equation}
\begin{aligned}
L(w,b,\xi,\alpha,\mu) &=
\frac{1}{2}\|w\|^2 + C\sum_{n=1}^N \xi_n \\
&\quad - \sum_{n=1}^N \alpha_n[t_n(w^T x_n + b)-1+\xi_n]
- \sum_{n=1}^N \mu_n \xi_n.
\end{aligned}
\end{equation}

\subsection{Điều kiện KKT}

\begin{align}
w &= \sum_{n=1}^N \alpha_n t_n x_n, \\
\sum_{n=1}^N \alpha_n t_n &= 0, \\
0 &\le \alpha_n \le C.
\end{align}

\subsection{Bài toán đối ngẫu}

\begin{equation}
\begin{aligned}
\min_{\alpha} \quad &
\frac{1}{2}\sum_{r=1}^N\sum_{c=1}^N
\alpha_r \alpha_c t_r t_c x_r^T x_c
- \sum_{n=1}^N \alpha_n \\
\text{s.t.} \quad &
0 \le \alpha_n \le C, \\
& \sum_{n=1}^N \alpha_n t_n = 0.
\end{aligned}
\end{equation}

%------------------------------------------------
\section{Công thức dự báo}

Sau khi tìm được $\alpha$ và $b$, hàm quyết định là:
\begin{equation}
y(x) = \sum_{n \in S} \alpha_n t_n x_n^T x + b,
\end{equation}
trong đó $S$ là tập các véc-tơ hỗ trợ.

Nhãn dự báo:
\[
\text{label} = \mathrm{sign}(y(x)).
\]

%------------------------------------------------
\section{Cài đặt với CVXOPT}

Bài toán đối ngẫu có dạng chuẩn:
\begin{equation}
\min_{\alpha} \quad
\frac{1}{2}\alpha^T K \alpha + p^T \alpha
\quad \text{s.t.} \quad
G\alpha \le h,\; A\alpha = b.
\end{equation}

Các ràng buộc hộp $0 \le \alpha_n \le C$ được mã hóa trong ma trận $G$ và $h$.

%------------------------------------------------

% SECTION 8: SVM KERNEL


\section{SVM hai lớp với lề mềm}
Xét tập huấn luyện $\{(x_i,t_i)\}_{i=1}^N$ với $t_i \in \{-1,+1\}$.
Bài toán đối ngẫu của SVM lề mềm được viết dưới dạng:

\begin{equation}
\alpha^* = \arg\min_{\alpha}
\frac{1}{2}\alpha^T K \alpha + p^T \alpha
\end{equation}

với các ràng buộc:
\begin{equation}
G\alpha \le h, \qquad A\alpha = b
\end{equation}

Trong đó, ma trận kernel $K$ được xác định bởi tích vô hướng giữa các điểm dữ liệu.

\subsection{Dự báo}
Giá trị bias $b$ được ước lượng bởi:
\begin{equation}
b = \frac{1}{N_M}
\left(
t_M - K_{MS}[\alpha_S \odot t_S]
\right)^T \mathbf{1}
\end{equation}

Hàm dự báo:
\begin{equation}
y = K_{BS}[\alpha_S \odot t_S] + b
\end{equation}

Nhãn dự đoán:
\begin{equation}
\text{label} = \text{sign}(y)
\end{equation}

\section{Khi đường biên giới phi tuyến}
Trong nhiều bài toán thực tế, dữ liệu không thể phân tách tuyến tính.
Giải pháp là ánh xạ dữ liệu thông qua hàm trích đặc trưng:
\[
\Phi: \mathbb{R}^d \rightarrow \mathcal{H}
\]

Tuy nhiên, việc tính trực tiếp $\Phi(x)$ có thể tốn kém hoặc không khả thi
khi không gian đặc trưng có số chiều rất lớn hoặc vô hạn.

\section{Phương pháp Kernel}
Phương pháp kernel cho phép tính:
\[
\langle \Phi(x_i), \Phi(x_j) \rangle
\]
mà không cần biết tường minh $\Phi(x)$, thông qua một hàm kernel:
\[
k(x_i,x_j)
\]

\subsection{Điều kiện Mercer}
Một hàm $k(x_i,x_j)$ là kernel hợp lệ nếu:
\begin{itemize}
\item Đối xứng: $k(x_i,x_j) = k(x_j,x_i)$
\item Bán định dương:
\[
\sum_{i=1}^N \sum_{j=1}^N c_i c_j k(x_i,x_j) \ge 0
\]
\end{itemize}

\section{Huấn luyện và dự báo với Kernel}
Ma trận Gram kernel:
\begin{equation}
K_{Gram} =
\begin{bmatrix}
k(x_1,x_1) & \cdots & k(x_1,x_N)\\
\vdots & \ddots & \vdots\\
k(x_N,x_1) & \cdots & k(x_N,x_N)
\end{bmatrix}
\end{equation}

Việc sử dụng kernel đảm bảo bài toán tối ưu là lồi và có nghiệm toàn cục.

\section{Các kernel thông dụng}
Một số kernel phổ biến trong thực tế:

\begin{itemize}
\item \textbf{Linear}:
\[
k(x,x') = x^T x'
\]

\item \textbf{Polynomial}:
\[
k(x,x') = (\gamma x^T x' + r)^d
\]

\item \textbf{RBF (Gaussian)}:
\[
k(x,x') = \exp(-\gamma \|x-x'\|^2)
\]

\item \textbf{Sigmoid}:
\[
k(x,x') = \tanh(\gamma x^T x' + r)
\]
\end{itemize}

Kernel RBF tương ứng với không gian đặc trưng vô hạn chiều.

\section{Thiết kế Kernel}
Việc thiết kế kernel phụ thuộc mạnh vào kiến thức miền (domain knowledge),
với mục tiêu:
\begin{itemize}
\item $k(x_i,x_j)$ lớn nếu $x_i, x_j$ cùng lớp
\item $k(x_i,x_j)$ nhỏ nếu khác lớp
\end{itemize}

\section{Minh họa}
Các thí nghiệm với kernel đa thức và kernel RBF cho thấy khả năng
phi tuyến hóa đường biên phân lớp một cách hiệu quả.


% SECTION 9 : PCA


\section{Mô tả bài toán}
Giả sử tập dữ liệu đầu vào:
\[
X =
\begin{bmatrix}
x_{1,1} & x_{1,2} & \cdots & x_{1,D} \\
x_{2,1} & x_{2,2} & \cdots & x_{2,D} \\
\vdots  & \vdots  & \ddots & \vdots  \\
x_{N,1} & x_{N,2} & \cdots & x_{N,D}
\end{bmatrix}
\]
trong đó:
\begin{itemize}
    \item $X \in \mathbb{R}^{N \times D}$;
    \item $D$ rất lớn và các chiều có tương quan với nhau.
\end{itemize}

\textbf{Mục tiêu:}
\begin{enumerate}
    \item Giảm số chiều từ $D$ xuống $M$ với $M \ll D$;
    \item Các đặc trưng mới không còn tương quan tuyến tính.
\end{enumerate}

\section{Kiến thức toán học liên quan}
\subsection{Phương sai và hiệp phương sai}
Trung bình của dữ liệu:
\[
\mu = \frac{1}{N}\sum_{n=1}^{N} x_n
\]

Dữ liệu được chuẩn hóa:
\[
z_n = x_n - \mu
\]

Ma trận hiệp phương sai:
\[
S = \frac{1}{N}\sum_{n=1}^{N}(x_n - \mu)(x_n - \mu)^T
\]

\subsection{Eigenvalue và Eigenvector}
Với ma trận vuông $A$, bài toán eigen:
\[
Au = \lambda u
\]
trong đó $u$ là eigenvector và $\lambda$ là eigenvalue.

\section{Cơ sở lý luận của PCA}
PCA có thể được nhìn theo hai cách:
\begin{itemize}
    \item Cực đại hóa phương sai của dữ liệu sau khi chiếu;
    \item Cực tiểu hóa sai số phục hồi dữ liệu.
\end{itemize}

Hai cách tiếp cận này là tương đương về mặt toán học.

\section{Cực đại hóa phương sai}
Với một vectơ đơn vị $u$, phương sai của dữ liệu khi chiếu lên $u$ là:
\[
\sigma^2 = u^T S u
\]

Bài toán tối ưu:
\[
\max_{u} \quad u^T S u
\quad \text{s.t.} \quad u^T u = 1
\]

Sử dụng nhân tử Lagrange dẫn đến:
\[
Su = \lambda u
\]

Do đó:
\begin{itemize}
    \item Các trục chính của PCA là các eigenvector của $S$;
    \item Phương sai tương ứng là các eigenvalue.
\end{itemize}

\section{Thu giảm số chiều}
Chọn $M$ eigenvector tương ứng với $M$ eigenvalue lớn nhất, tạo thành ma trận:
\[
\hat{U} = [u_1, u_2, \dots, u_M]
\]

Chiếu dữ liệu:
\[
X_{\text{PCA}} = (X - \mu^T)\hat{U}
\]

Phục hồi xấp xỉ:
\[
\hat{X} = \mu^T + X_{\text{PCA}}\hat{U}^T
\]

\section{PCA qua API}
Ví dụ PCA trong \texttt{scikit-learn}:
\begin{verbatim}
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
pca.fit(X)
print(pca.explained_variance_ratio_)
\end{verbatim}

\section{Singular Value Decomposition (SVD)}
Phân rã SVD:
\[
X = U S V^T
\]

\begin{itemize}
    \item PCA thực hiện eigen-decomposition trên ma trận hiệp phương sai;
    \item SVD phân rã trực tiếp trên ma trận dữ liệu và có độ ổn định số cao hơn.
\end{itemize}

\section{Ứng dụng của PCA}
\begin{itemize}
    \item Nén dữ liệu;
    \item Trực quan hóa dữ liệu nhiều chiều;
    \item Tiền xử lý cho học máy;
    \item Nhận dạng mẫu và xử lý ảnh.
\end{itemize}


% SECTION 10: LDA
% ==========================================================
\section{Giới thiệu về LDA}


\subsection{Đầu vào}

Cho tập dữ liệu:
\[
X =
\begin{bmatrix}
x_{1,1} & x_{1,2} & \cdots & x_{1,D} \\
x_{2,1} & x_{2,2} & \cdots & x_{2,D} \\
\vdots  & \vdots  & \ddots & \vdots  \\
x_{N,1} & x_{N,2} & \cdots & x_{N,D}
\end{bmatrix},
\quad
t =
\begin{bmatrix}
t_1 \\ t_2 \\ \vdots \\ t_N
\end{bmatrix}
\]

Trong đó:
\begin{itemize}
  \item $X \in \mathbb{R}^{N \times D}$, với $D$ thường rất lớn.
  \item $t_k \in \{1,2,\ldots,C\}$ là nhãn lớp của điểm dữ liệu thứ $k$.
\end{itemize}

\subsection{Mục tiêu}

Mục tiêu của LDA là:
\begin{enumerate}
  \item Giảm số chiều từ $D$ xuống $M$, với $M \le C - 1$.
  \item Dữ liệu sau khi chiếu có độ phân tách giữa các lớp là lớn nhất.
\end{enumerate}

% ==========================================================
\section{LDA qua API}

Ví dụ sử dụng \texttt{Scikit-learn}:

\begin{verbatim}
from sklearn import datasets
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

iris = datasets.load_iris()
X = iris.data
y = iris.target

lda = LinearDiscriminantAnalysis(n_components=2)
X_r = lda.fit(X, y).transform(X)
\end{verbatim}

% ==========================================================
\section{Bài toán tối ưu}

\subsection{Tâm của mỗi lớp}

Với lớp $k$:
\[
\mathbf{m}_k = \frac{1}{N_k} \sum_{n \in C_k} \mathbf{x}_n
\]

\subsection{Between-class scatter matrix}

\[
S_B = (\mathbf{m}_2 - \mathbf{m}_1)(\mathbf{m}_2 - \mathbf{m}_1)^T
\]

\subsection{Within-class scatter matrix}

\[
S_W = \sum_{k=1}^{C} \sum_{n \in C_k}
(\mathbf{x}_n - \mathbf{m}_k)(\mathbf{x}_n - \mathbf{m}_k)^T
\]

\subsection{Hàm mục tiêu của Fisher}

\[
J(\mathbf{w}) =
\frac{\mathbf{w}^T S_B \mathbf{w}}
     {\mathbf{w}^T S_W \mathbf{w}}
\]

Mục tiêu:
\[
\mathbf{w}^* = \arg\max_{\mathbf{w}} J(\mathbf{w})
\]

% ==========================================================
\section{Tìm nghiệm}

Giải bài toán tối ưu dẫn đến phương trình trị riêng:
\[
S_W^{-1} S_B \mathbf{w} = \lambda \mathbf{w}
\]

Hướng chiếu tối ưu là:
\[
\mathbf{w} \propto S_W^{-1}(\mathbf{m}_2 - \mathbf{m}_1)
\]

% ==========================================================
\section{Trường hợp có $C$ lớp}

\subsection{Hàm mục tiêu tổng quát}

\[
J(W) =
\frac{\text{trace}(W^T S_B W)}
     {\text{trace}(W^T S_W W)}
\]

\subsection{Số chiều tối đa}

Số chiều tối đa có thể chọn là:
\[
M \le C - 1
\]

Do ma trận $S_B$ có hạng tối đa là $C-1$.

\subsection{Giải thuật LDA}

\begin{enumerate}
  \item Tính $S_B$ và $S_W$.
  \item Tính $A = S_W^{-1} S_B$.
  \item Thực hiện SVD hoặc eigen-decomposition.
  \item Chọn $M$ eigenvector tương ứng với eigenvalue lớn nhất.
  \item Chiếu dữ liệu: $\hat{X} = (X - m^T)W$.
\end{enumerate}

% ==========================================================

% SECTION 11: ENSEMBLE 

% --------------------
\section{Bias--Variance Perspective}

Prediction error can be decomposed into bias and variance. Bias results from
overly simplistic assumptions, while variance reflects sensitivity to training
data fluctuations. Ensemble learning aims to reduce variance by averaging
predictions of multiple weakly correlated models. For regression, the variance
of an ensemble predictor can be approximated as
\[
\mathrm{Var}\left(
\frac{1}{M} \sum_{m=1}^{M} \hat{y}^{(m)}
\right)
\approx
\frac{1}{M^2} \sum_{m=1}^{M} \mathrm{Var}(\hat{y}^{(m)}).
\]

% --------------------
\section{Bagging (Bootstrap Aggregating)}

Bagging is designed to reduce variance, particularly for unstable learners such
as decision trees.

\subsection{Method Description}

Given a training dataset
\[
D = \{(x_i, y_i)\}_{i=1}^{n},
\]
Bagging constructs an ensemble of $M$ models as follows:
\begin{enumerate}[label=\arabic*.]
\item Draw $M$ bootstrap datasets $D_1, D_2, \dots, D_M$ by sampling $n$ points
with replacement from $D$.
\item Train a base learner on each bootstrap dataset to obtain models
$h_1, h_2, \dots, h_M$.
\item Combine predictions of all models:
\[
\hat{y}(x) =
\begin{cases}
\frac{1}{M}\sum_{m=1}^{M} h_m(x), & \text{regression}, \\
\text{majority vote}, & \text{classification}.
\end{cases}
\]
\end{enumerate}

\subsection{Properties}

Bagging is simple, highly parallelizable, and effective at variance reduction.
However, it requires storing many models and results in slower inference.

% --------------------
\section{Random Forest}

Random Forest extends Bagging by introducing randomness in feature selection.
Each tree is trained on a bootstrap dataset, and at each split only a random
subset of features is considered.

\subsection{Training Procedure}

For each tree:
\begin{enumerate}[label=\arabic*.]
\item Sample a bootstrap dataset from the training set.
\item Grow a decision tree by recursively splitting nodes.
\item At each split, randomly select a subset of features
$F_{\text{sub}} \subset \{1,\dots,d\}$.
\item Choose the best split using only features in $F_{\text{sub}}$.
\end{enumerate}

Typical choices are $|F_{\text{sub}}|=\sqrt{d}$ for classification and
$|F_{\text{sub}}|=d/3$ for regression.

% --------------------
\section{Boosting}

Boosting methods train models sequentially, where each model focuses on samples
misclassified by previous ones. Unlike Bagging, Boosting can reduce both bias
and variance.

\subsection{AdaBoost}

For binary classification with $y_i \in \{-1,+1\}$, AdaBoost maintains a weight
distribution over training samples. At iteration $t$, a weak learner $h_t$ is
trained using weighted data. The final classifier is
\[
H(x) = \mathrm{sign}
\left(
\sum_{t=1}^{T} \alpha_t h_t(x)
\right),
\]
where $\alpha_t$ is determined by the weighted classification error of $h_t$.

\subsection{Gradient Boosting}

Gradient Boosting views ensemble construction as gradient descent in function
space. At each iteration, a new weak learner is fitted to the negative gradient
of the loss function with respect to current predictions.

% --------------------
\section{Voting and Stacking}

\subsection{Voting}

Voting combines predictions of multiple models using a fixed rule such as
majority voting or probability averaging. It is simple and often serves as a
strong baseline.

\subsection{Stacking}

Stacking trains a meta-learner on predictions of base models. To avoid
overfitting, cross-validation is used to generate out-of-fold predictions, which
are then used as inputs for the meta-model.

% --------------------
\section{Comparison and Practical Considerations}

Bagging is most effective for high-variance models, Boosting can significantly
improve accuracy but is sensitive to noise, and Stacking offers the greatest
flexibility at the cost of increased complexity. In practice, Random Forests
and Gradient Boosting are strong default choices for tabular data.

% --------------------

% SECTION 12: GENETIC ALGORITHM

\section{Key Components of Genetic Algorithms}

\subsection{Representation (Encoding)}

A solution is encoded as a chromosome. Common encoding methods include:
\begin{itemize}
    \item \textbf{Binary encoding}: chromosomes consist of bits (0 or 1)
    \item \textbf{Real-valued encoding}: genes are real numbers
    \item \textbf{Permutation encoding}: chromosomes represent ordered sequences
    \item \textbf{Tree encoding}: solutions are tree structures (used in genetic programming)
\end{itemize}

\subsection{Fitness Function}

The fitness function $f(x)$ evaluates the quality of a solution $x$.
For minimization problems, a transformation is typically applied, such as:
\[
f_{\text{max}}(x) = \frac{1}{1 + f_{\text{min}}(x)}
\]

The fitness function should be computationally efficient, as it is evaluated
many times during the evolutionary process.

\subsection{Selection}

Selection chooses parent solutions based on fitness.
Popular methods include:
\begin{itemize}
    \item Roulette wheel selection
    \item Rank selection
    \item Tournament selection
    \item Elitism
\end{itemize}

Elitism ensures that the best individuals are preserved across generations.

\subsection{Crossover}

Crossover combines genetic material from two parents to produce offspring.
Common techniques include:
\begin{itemize}
    \item Single-point crossover
    \item Two-point crossover
    \item Uniform crossover
    \item Arithmetic crossover (for real-valued encoding)
\end{itemize}

\subsection{Mutation}

Mutation introduces random changes to maintain population diversity.
Typical mutation strategies include:
\begin{itemize}
    \item Bit flipping for binary encoding
    \item Gaussian or uniform noise for real-valued encoding
    \item Swap or inversion for permutation encoding
\end{itemize}

\section{Genetic Algorithm Framework}

A standard genetic algorithm follows these steps:
\begin{enumerate}
    \item Initialize a population of $N$ individuals
    \item Evaluate fitness of each individual
    \item Repeat until a termination condition is met:
    \begin{enumerate}
        \item Select parents based on fitness
        \item Apply crossover to generate offspring
        \item Apply mutation to offspring
        \item Evaluate fitness of new individuals
        \item Form the next generation (with optional elitism)
    \end{enumerate}
    \item Return the best solution found
\end{enumerate}

Termination conditions may include a maximum number of generations,
fitness convergence, stagnation, or time limits.

\section{Simple Example}

Consider maximizing the function:
\[
f(x) = x^2, \quad x \in \{0,1,\ldots,15\}
\]

Binary encoding with 4 bits is used.
An example initial population is shown in Table~\ref{tab:initpop}.

\begin{table}[h]
\centering
\caption{Initial population}
\label{tab:initpop}
\begin{tabular}{cccc}
\toprule
Individual & Binary & $x$ & $f(x)$ \\
\midrule
A & 0110 & 6 & 36 \\
B & 1001 & 9 & 81 \\
C & 0011 & 3 & 9 \\
D & 1100 & 12 & 144 \\
\bottomrule
\end{tabular}
\end{table}

After selection, crossover, and mutation, the population gradually
converges toward the optimal solution $x=15$.

\section{Parameters and Tuning}

Key parameters include:
\begin{itemize}
    \item Population size ($N$)
    \item Crossover probability ($p_c$)
    \item Mutation probability ($p_m$)
\end{itemize}

Typical values are:
\begin{itemize}
    \item $N = 20$--$200$
    \item $p_c = 0.6$--$0.9$
    \item $p_m = 0.001$--$0.1$
\end{itemize}

Parameter selection is problem-dependent and often requires empirical tuning.

\section{Advantages and Disadvantages}

\subsection{Advantages}
\begin{itemize}
    \item Global search capability
    \item No requirement for gradient information
    \item Parallelizable structure
    \item Flexible solution representation
\end{itemize}

\subsection{Disadvantages}
\begin{itemize}
    \item No guarantee of global optimality
    \item Computationally expensive
    \item Sensitive to parameter settings
    \item Risk of premature convergence
\end{itemize}

\section{Applications}

Genetic Algorithms have been successfully applied in:
\begin{itemize}
    \item Combinatorial optimization (TSP, scheduling)
    \item Machine learning (feature selection, hyperparameter tuning)
    \item Engineering design (antennas, circuits)
    \item Bioinformatics (protein structure prediction)
    \item Game AI and procedural content generation
\end{itemize}

\section{Variants and Extensions}

Popular GA variants include:
\begin{itemize}
    \item Real-Coded Genetic Algorithms (RCGA)
    \item Differential Evolution (DE)
    \item Genetic Programming (GP)
    \item Multi-objective Genetic Algorithms (e.g., NSGA-II)
\end{itemize}

These variants extend GA to continuous, programmatic,
and multi-objective optimization problems.


\end{multicols}

% ==================================================
\end{document}
