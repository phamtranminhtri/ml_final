\documentclass[10pt,a4paper]{article}

% ---------------- Packages ----------------
\usepackage[utf8]{inputenc}
\usepackage[T5]{fontenc}
\usepackage[vietnamese]{babel}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{enumitem}

\usepackage{multicol}

\geometry{margin=0.5cm}
\setlength{\parindent}{0pt}

% ---------------- Title ----------------
\title{Hồi quy Logistic cho Bài toán Phân loại Hai lớp}
\author{Lê Thành Sách\\
Khoa Khoa học \& Kỹ thuật Máy tính\\
Trường Đại học Bách Khoa -- ĐHQG TP.HCM\\
\texttt{ltsach@hcmut.edu.vn}}
\date{09/09/2019}

\begin{document}
% \maketitle

% \tableofcontents
% \newpage

\begin{multicols}{3}

\section{Định nghĩa bài toán}

\subsection{Đầu vào}

Cho tập dữ liệu gồm $N$ mẫu:
\begin{itemize}
    \item Tập các vector đặc trưng:
    \[
        \mathbf{x}_n = [x_{n,0}, x_{n,1}, \dots, x_{n,D-1}]^T,
        \quad n = 1, \dots, N
    \]
    với $x_{n,0} = 1$.
    
    \item Vector nhãn:
    \[
        \mathbf{t} = [t_1, t_2, \dots, t_N]^T
    \]
\end{itemize}

Dữ liệu được tổ chức dưới dạng:
\[
\mathbf{X} =
\begin{bmatrix}
1 & x_{1,1} & \dots & x_{1,D-1} \\
1 & x_{2,1} & \dots & x_{2,D-1} \\
\vdots & \vdots & \ddots & \vdots \\
1 & x_{N,1} & \dots & x_{N,D-1}
\end{bmatrix},
\quad
\mathbf{t} =
\begin{bmatrix}
t_1 \\ t_2 \\ \vdots \\ t_N
\end{bmatrix}
\]

\subsection{Giả thiết}

Giả sử nhãn được sinh theo mô hình:
\begin{equation}
t = h(\mathbf{x}) + \varepsilon
\end{equation}

Trong đó:
\begin{itemize}
    \item $h(\mathbf{x})$: hàm hồi quy tối ưu (chưa biết)
    \item $\varepsilon \sim \mathcal{N}(0, \sigma^2)$: nhiễu Gauss
\end{itemize}

Các mẫu dữ liệu và nhiễu được giả thiết là \textit{i.i.d}.

\subsection{Đầu ra}

Mô hình hồi quy tuyến tính:
\begin{equation}
\hat{y}(\mathbf{x}, \mathbf{w}) = \mathbf{w}^T \mathbf{x}
\end{equation}

với:
\[
\mathbf{w} = [w_0, w_1, \dots, w_{D-1}]^T
\]

% =====================================================
\section{Giải bài toán}

\subsection{Nguyên tắc chung}

Bài toán được giải bằng cách:
\begin{itemize}
    \item Xây dựng hàm hợp lý
    \item Cực đại hóa hợp lý (Maximum Likelihood)
\end{itemize}

\subsection{Hợp lý cực đại}

Với giả thiết nhiễu Gauss:
\begin{equation}
p(t_n | \mathbf{x}_n, \mathbf{w}, \beta)
= \mathcal{N}(t_n | \mathbf{w}^T \mathbf{x}_n, \beta^{-1})
\end{equation}

Hàm negative log-likelihood:
\begin{equation}
L(\mathbf{w}, \beta)
= \beta E_D(\mathbf{w})
- \frac{N}{2} \log \beta
+ \frac{N}{2} \log(2\pi)
\end{equation}

với:
\begin{equation}
E_D(\mathbf{w})
= \frac{1}{2}\sum_{n=1}^N (t_n - \mathbf{w}^T \mathbf{x}_n)^2
\end{equation}

\subsection{Nghiệm giải tích}

Cực tiểu $E_D(\mathbf{w})$ cho nghiệm:
\begin{equation}
\mathbf{w}_{ML} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{t}
\end{equation}

Ước lượng phương sai nhiễu:
\begin{equation}
\beta_{ML}^{-1}
= \frac{1}{N}\sum_{n=1}^N
(t_n - \mathbf{w}_{ML}^T\mathbf{x}_n)^2
\end{equation}

\subsection{Giải thuật lặp (Gradient Descent)}

Cập nhật tham số:
\begin{equation}
\mathbf{w}^{(t)}
= \mathbf{w}^{(t-1)} - \eta \nabla E_D(\mathbf{w})
\end{equation}

% =====================================================
\section{Hồi quy cho quan hệ phi tuyến}

Ánh xạ dữ liệu sang không gian đặc trưng mới:
\[
\mathbf{x} \rightarrow
\boldsymbol{\phi}(\mathbf{x})
= [\phi_0(\mathbf{x}), \dots, \phi_{M-1}(\mathbf{x})]
\]

Sau đó áp dụng hồi quy tuyến tính trên không gian mới.

% =====================================================
\section{Đánh giá mô hình}

\subsection{Dự báo}

\begin{equation}
\hat{\mathbf{y}} = \mathbf{X}\mathbf{w}_{ML}
\end{equation}

\subsection{Các độ đo}

Mean Squared Error:
\begin{equation}
\mathrm{MSE}
= \frac{1}{N}\sum_{n=1}^N (t_n - \hat{y}_n)^2
\end{equation}

Root Mean Squared Error:
\begin{equation}
\mathrm{RMSE} = \sqrt{\mathrm{MSE}}
\end{equation}

% =====================================================
\section{Hạn chế quá khớp}

\subsection{Ridge Regression}

\begin{equation}
L(\mathbf{w})
= \frac{1}{2}\sum_{n=1}^N (t_n - \mathbf{w}^T\mathbf{x}_n)^2
+ \frac{\lambda}{2}\mathbf{w}^T\mathbf{w}
\end{equation}

Nghiệm:
\begin{equation}
\mathbf{w}_{ridge}
= (\lambda \mathbf{I} + \mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{t}
\end{equation}

\subsection{LASSO}

\begin{equation}
L(\mathbf{w})
= \frac{1}{2}\sum_{n=1}^N (t_n - \mathbf{w}^T\mathbf{x}_n)^2
+ \lambda \sum_{m=1}^M |w_m|
\end{equation}

% =====================================================
\section{Dự báo cho nhiều biến}

Với $K$ biến đầu ra:
\begin{equation}
\mathbf{W}
= (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{T}
\end{equation}

Trong đó:
\begin{itemize}
    \item $\mathbf{T} \in \mathbb{R}^{N \times K}$
    \item $\mathbf{W} \in \mathbb{R}^{M \times K}$
\end{itemize}


% ==================================================
\section{Giới thiệu bài toán}

Mục tiêu của bài toán là xây dựng một mô hình dự đoán từ tập huấn luyện để khi nhận một mẫu dữ liệu mới $x$, mô hình có thể dự đoán nhãn của mẫu đó.

Bài giảng này tập trung vào việc xây dựng \textbf{mô hình tuyến tính} cho bài toán phân loại hai lớp, trong đó đường biên phân lớp là tuyến tính.

% --------------------------------------------------
\subsection{Đầu vào}

\subsubsection{Dữ liệu đầu vào}

Ma trận dữ liệu:
\[
X =
\begin{bmatrix}
1 & x_{1,1} & x_{1,2} & \cdots & x_{1,(M-1)} \\
1 & x_{2,1} & x_{2,2} & \cdots & x_{2,(M-1)} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_{N,1} & x_{N,2} & \cdots & x_{N,(M-1)}
\end{bmatrix}
\]

\begin{itemize}
    \item Mỗi hàng tương ứng với một điểm dữ liệu
    \item $X$ có kích thước $N \times M$
\end{itemize}

\subsubsection{Tập nhãn}

\begin{itemize}
    \item Bài toán có hai nhãn
    \item Mỗi nhãn được mã hóa bằng chỉ số $\{0,1\}$
\end{itemize}

\subsubsection{Nhãn dữ liệu}

\[
t = (t_1, t_2, \ldots, t_N)^T
\]

\subsubsection{Quy ước}

\begin{itemize}
    \item $X$: ma trận dữ liệu, kích thước $N \times M$
    \item $t$: vector nhãn
    \item $y$: biểu diễn dạng số của nhãn
    \item $N$: số điểm dữ liệu
    \item $M$: số đặc trưng
    \item $\hat{y}$: giá trị dự báo từ mô hình
\end{itemize}

% ==================================================
\section{Phương pháp xây dựng mô hình}

\subsection{Ý tưởng}

\begin{itemize}
    \item Hai lớp: $C_0$ và $C_1$
    \item Mô hình dự báo xác suất $x$ thuộc lớp $C_1$
    \item Xác suất thuộc lớp $C_0$ là $1 - \hat{y}$
\end{itemize}

Bên trong mô hình:
\begin{enumerate}
    \item Sử dụng mô hình tuyến tính:
    \[
    z = w^T x
    \]
    \item Đưa $z$ qua hàm sigmoid
\end{enumerate}

\subsection{Hàm sigmoid}

\[
\sigma(z) = \frac{1}{1 + e^{-z}}
\]

\subsection{Mô hình dự báo}

\begin{equation}
\hat{y} = p(C_1|x,w) = \sigma(w^T x)
\label{eq:logistic}
\end{equation}

Quy tắc phân lớp:
\begin{itemize}
    \item Nếu $\hat{y} \ge \lambda$ thì $x \in C_1$
    \item Ngược lại, $x \in C_0$
\end{itemize}

% ==================================================
\section{Ước lượng tham số của mô hình}

\subsection{Xây dựng hàm mục tiêu}

Với một điểm dữ liệu $(x,y)$:
\[
p(y|x,w) =
\hat{y}^y (1-\hat{y})^{1-y}
\]

Với $N$ điểm dữ liệu:
\[
p(t|X,w) = \prod_{n=1}^{N} \hat{y}_n^{y_n} (1-\hat{y}_n)^{1-y_n}
\]

Sử dụng \textbf{negative log-likelihood}:
\begin{equation}
L(w) = -\sum_{n=1}^{N}
\left[
y_n \log \hat{y}_n + (1-y_n)\log(1-\hat{y}_n)
\right]
\label{eq:loss}
\end{equation}

Hàm này còn được gọi là \textbf{cross-entropy}.

\subsection{Tìm hệ số của mô hình}

Gradient của hàm mất mát:
\begin{equation}
\nabla L(w) = \sum_{n=1}^{N} (\hat{y}_n - y_n)x_n
= X^T(\hat{y} - y)
\end{equation}

\subsection{Giải thuật lặp với đạo hàm bậc 2}

Ma trận Hessian:
\begin{equation}
H = \nabla^2 L(w)
= \sum_{n=1}^{N} \hat{y}_n(1-\hat{y}_n)x_n x_n^T
= X^T R X
\end{equation}

Trong đó $R$ là ma trận đường chéo:
\[
R_{nn} = \hat{y}_n(1-\hat{y}_n)
\]

Phương pháp sử dụng:
\begin{itemize}
    \item Gradient Descent
    \item Newton--Raphson
    \item Iterative Re-weighted Least Squares (IRLS)
\end{itemize}

\section{Giới thiệu bài toán}

Bài toán phân loại nhiều lớp (multi-class classification) nhằm xây dựng
một mô hình dự đoán nhãn của dữ liệu đầu vào, trong đó mỗi mẫu dữ liệu
thuộc về một trong $K$ lớp rời rạc.

Mục tiêu của bài toán là học được một mô hình từ tập huấn luyện để
dự đoán chính xác nhãn của các mẫu dữ liệu mới.

% ==================================================
\section{Dữ liệu đầu vào}

\subsection{Ma trận dữ liệu}

Giả sử tập dữ liệu đầu vào được biểu diễn bởi ma trận:
\[
X =
\begin{bmatrix}
1 & x_{1,1} & x_{1,2} & \cdots & x_{1,(M-1)} \\
1 & x_{2,1} & x_{2,2} & \cdots & x_{2,(M-1)} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_{N,1} & x_{N,2} & \cdots & x_{N,(M-1)}
\end{bmatrix}
\]
trong đó $X \in \mathbb{R}^{N \times M}$.

\subsection{Nhãn và biểu diễn one-hot}

Mỗi nhãn được mã hóa dưới dạng véctơ one-hot kích thước $K$.
Ví dụ với $K=4$:

\begin{center}
\begin{tabular}{ccc}
\toprule
Nhãn & Chỉ số & One-hot \\
\midrule
Chó   & 0 & [1, 0, 0, 0] \\
Mèo  & 1 & [0, 1, 0, 0] \\
Chuột& 2 & [0, 0, 1, 0] \\
Thỏ  & 3 & [0, 0, 0, 1] \\
\bottomrule
\end{tabular}
\end{center}

% ==================================================
\section{Mô hình tuyến tính với Softmax}

\subsection{Mô hình dự báo}

Ma trận tham số của mô hình:
\[
W =
\begin{bmatrix}
w_1^T \\
w_2^T \\
\vdots \\
w_K^T
\end{bmatrix}
\in \mathbb{R}^{K \times M}
\]

Các bước tính toán:
\begin{align}
Z &= XW^T \quad (N \times K) \\
\hat{Y} &= \text{softmax}(Z)
\end{align}

Hàm softmax được định nghĩa:
\[
\hat{y}_k = \frac{\exp(z_k)}{\sum_{i=1}^{K} \exp(z_i)}
\]

\subsection{Dự đoán}

Nhãn dự đoán của mẫu dữ liệu được xác định bằng:
\[
\text{prediction} = \arg\max_k \hat{y}_k
\]

% ==================================================
\section{Hàm mục tiêu và tối ưu}

\subsection{Hàm hợp lý}

Xác suất của tập nhãn:
\[
p(t|X,W) = \prod_{n=1}^{N} \prod_{k=1}^{K} \hat{y}_{n,k}^{y_{n,k}}
\]

\subsection{Hàm mất mát Cross-Entropy}

Hàm mất mát được xây dựng bằng cách lấy log và đổi dấu:
\[
L(W) = -\sum_{n=1}^{N}\sum_{k=1}^{K} y_{n,k}\log(\hat{y}_{n,k})
\]

Mục tiêu là tìm $W$ sao cho $L(W)$ đạt giá trị nhỏ nhất.

% ==================================================
\section{Ước lượng tham số}

\subsection{Gradient Descent}

Gradient của hàm mất mát đối với đầu vào softmax:
\[
\frac{\partial L}{\partial z} = (\hat{y} - y)^T
\]

Gradient theo tham số:
\[
\Delta W = (\hat{y} - y)^T x^T
\]

Cập nhật trọng số:
\[
W \leftarrow W - \eta \Delta W
\]
trong đó $\eta$ là hệ số học.

% ==================================================
\section{Mở rộng cho đường biên phi tuyến}

Để xử lý dữ liệu không phân tách tuyến tính, có thể:
\begin{itemize}
\item Biến đổi đặc trưng sang không gian mới
\item Sử dụng hàm cơ sở đa thức
\item Áp dụng mạng nơ-ron để học đặc trưng
\end{itemize}

% ==================================================
\section{Kết luận}

Mô hình tuyến tính kết hợp với softmax là một phương pháp nền tảng
cho bài toán phân loại nhiều lớp, dễ cài đặt, hiệu quả và là cơ sở
cho các mô hình học sâu phức tạp hơn.

\section{Linear Regression and Logistic Regression: Recap}

\subsection{Linear Regression (Single Output)}

Given an input feature vector $x \in \mathbb{R}^d$, linear regression predicts
a scalar output:
\begin{equation}
\hat{y} = w^\top x + b
\end{equation}

The model is trained by minimizing the Mean Squared Error (MSE):
\begin{equation}
\mathrm{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\end{equation}

\textbf{Limitation:} Only linear relationships can be modeled.

\subsection{Linear Regression (Multiple Outputs)}

For multiple outputs $y \in \mathbb{R}^m$:
\begin{equation}
\hat{y} = W^\top x + b, \quad W \in \mathbb{R}^{d \times m}
\end{equation}

\subsection{Logistic Regression (Binary Classification)}

Logistic regression models the probability:
\begin{equation}
\hat{p} = P(y=1|x) = \sigma(w^\top x + b),
\quad \sigma(z)=\frac{1}{1+e^{-z}}
\end{equation}

Binary Cross-Entropy loss:
\begin{equation}
\mathcal{L}_{\text{BCE}} =
-\frac{1}{n}\sum_{i=1}^{n}
\left[y_i \log \hat{p}_i + (1-y_i)\log(1-\hat{p}_i)\right]
\end{equation}

\subsection{Softmax Regression (Multiclass)}

For $K$ classes:
\begin{equation}
\hat{p}_k =
\frac{\exp(w_k^\top x + b_k)}
{\sum_{j=1}^{K}\exp(w_j^\top x + b_j)}
\end{equation}

\textbf{Key limitation of linear models:}
decision boundaries are linear and cannot represent complex nonlinear patterns.

% ======================================================
\section{MLP: Computational Architecture View}

An MLP consists of:
\begin{itemize}
    \item A \textbf{feature transformer}: stacked linear layers with nonlinear activations.
    \item An \textbf{output head}:
    \begin{itemize}
        \item Linear head for regression
        \item Logistic or softmax head for classification
    \end{itemize}
\end{itemize}

\textbf{Core idea:}
deep learning = nonlinear feature extraction + simple linear head.

% ======================================================
\section{MLP: Mathematical Model}

\subsection{Forward Pass}

Let $h^{(0)} = x$. Each hidden layer computes:
\begin{equation}
h^{(l)} = \phi\left(W^{(l)}h^{(l-1)} + b^{(l)}\right),
\quad l = 1,\dots,L
\end{equation}

where $\phi(\cdot)$ is a nonlinear activation function.

\subsection{Output Layer}

\textbf{Regression:}
\begin{equation}
\hat{y} = W^{(L+1)}h^{(L)} + b^{(L+1)}
\end{equation}

\textbf{Classification (Softmax):}
\begin{equation}
\hat{p}_k =
\frac{\exp(w_k^\top h^{(L)} + b_k)}
{\sum_{j}\exp(w_j^\top h^{(L)} + b_j)}
\end{equation}

\subsection{Function Composition View}

An MLP is a composition of functions:
\begin{equation}
f(x;\theta) =
f^{(L+1)} \circ \phi \circ f^{(L)} \circ \cdots \circ \phi \circ f^{(1)}(x)
\end{equation}

More layers imply higher representation power.

% ======================================================
\section{MLP: Layers}

\subsection{Fully Connected (Linear) Layer}

For a single sample:
\begin{equation}
y = Wx + b
\end{equation}

For a mini-batch $X \in \mathbb{R}^{B \times N}$:
\begin{equation}
Y = XW^\top + \mathbf{1}b^\top
\end{equation}

\subsection{Activation Functions}

\paragraph{Sigmoid}
\begin{equation}
\sigma(z)=\frac{1}{1+e^{-z}}
\end{equation}

\paragraph{Tanh}
\begin{equation}
\tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}
\end{equation}

\paragraph{ReLU}
\begin{equation}
\mathrm{ReLU}(z)=\max(0,z)
\end{equation}

\paragraph{Leaky ReLU}
\begin{equation}
\mathrm{LReLU}(z)=
\begin{cases}
z, & z\ge 0\\
\alpha z, & z<0
\end{cases}
\end{equation}

\paragraph{SiLU (Swish)}
\begin{equation}
\mathrm{SiLU}(z)=z\sigma(z)
\end{equation}

% ======================================================
\section{MLP: Summary}

\begin{itemize}
    \item MLP extends linear models by introducing nonlinear feature transformations.
    \item Architecture: stacked fully connected layers + activations.
    \item Can approximate complex nonlinear functions.
    \item Powerful but prone to overfitting without sufficient data or regularization.
\end{itemize}

\section{Giới thiệu bài toán}

\subsection{Đầu vào}

Dữ liệu huấn luyện gồm:
\begin{itemize}
    \item Ma trận dữ liệu:
    \[
    X =
    \begin{bmatrix}
    x_{1,1} & x_{1,2} & \cdots & x_{1,(M-1)} \\
    x_{2,1} & x_{2,2} & \cdots & x_{2,(M-1)} \\
    \vdots  & \vdots  & \ddots & \vdots \\
    x_{N,1} & x_{N,2} & \cdots & x_{N,(M-1)}
    \end{bmatrix}
    \]
    với $X \in \mathbb{R}^{N \times (M-1)}$.
    
    \item Véc-tơ nhãn:
    \[
    \mathbf{t} =
    \begin{bmatrix}
    t_1 \\ t_2 \\ \vdots \\ t_N
    \end{bmatrix}, \quad t_n \in \{-1, +1\}
    \]
\end{itemize}

\subsection{Giả thiết}

Dữ liệu thuộc hai lớp có thể \textbf{phân tách tuyến tính}, tức tồn tại một siêu phẳng sao cho các điểm mang nhãn $+1$ và $-1$ nằm ở hai phía khác nhau.

\subsection{Mục tiêu}

Xác định đường biên quyết định:
\[
\mathbf{w}^T \mathbf{x} + b = 0
\]
sao cho \textbf{lề (margin)} giữa hai lớp là lớn nhất.

\subsection{SVM với \texttt{scikit-learn}}

Ví dụ sử dụng SVM trong \texttt{scikit-learn}:
\begin{verbatim}
from sklearn import svm
X = [[0, 0], [1, 1]]
y = [0, 1]
clf = svm.SVC()
clf.fit(X, y)
clf.predict([[2., 2.]])
\end{verbatim}

% =====================================================
\section{Phương pháp xây dựng bộ phân lớp}

\subsection{Nguyên tắc}

Quy trình gồm ba bước chính:
\begin{enumerate}
    \item Chuyển về bài toán tối ưu có ràng buộc với mục tiêu cực đại lề (bài toán gốc).
    \item Chuyển sang bài toán đối ngẫu (Dual problem).
    \item Giải bài toán tối ưu bằng các thư viện tối ưu lồi như \texttt{CVXOPT}.
\end{enumerate}

% =====================================================
\section{Bài toán gốc (Primal Problem)}

\subsection{Khoảng cách từ điểm đến đường thẳng}

Siêu phẳng trong không gian đặc trưng $(M-1)$ chiều:
\[
\mathbf{w}^T \mathbf{x} + b = 0
\]

Khoảng cách có dấu từ điểm $\mathbf{x}$ đến siêu phẳng:
\[
d(\mathbf{x}) = \frac{\mathbf{w}^T \mathbf{x} + b}{\|\mathbf{w}\|}
\]

Khoảng cách hình học:
\[
|d(\mathbf{x})| = \frac{|\mathbf{w}^T \mathbf{x} + b|}{\|\mathbf{w}\|}
\]

\subsection{Hàm quyết định}

Hàm quyết định:
\[
y(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b
\]

Quy tắc phân lớp:
\[
\text{class}(\mathbf{x}) = \text{sign}(y(\mathbf{x}))
\]

\subsection{Lề (Margin)}

Lề trên tập huấn luyện:
\[
m_{\mathbf{w}} = \min_{n} \frac{t_n(\mathbf{w}^T \mathbf{x}_n + b)}{\|\mathbf{w}\|}
\]

\subsection{Cực đại lề}

Có thể chuẩn hóa sao cho:
\[
t_n(\mathbf{w}^T \mathbf{x}_n + b) \ge 1, \quad \forall n
\]

\subsection{Hàm mục tiêu}

Cực đại lề tương đương với bài toán:
\[
\min_{\mathbf{w}, b} \frac{1}{2}\|\mathbf{w}\|^2
\]

với ràng buộc:
\[
t_n(\mathbf{w}^T \mathbf{x}_n + b) \ge 1, \quad n=1,\dots,N
\]

\subsection{Bài toán gốc}

\[
\begin{aligned}
\mathbf{w}^*, b^* = \arg\min_{\mathbf{w}, b} \quad &
\frac{1}{2}\|\mathbf{w}\|^2 \\
\text{s.t.} \quad &
t_n(\mathbf{w}^T \mathbf{x}_n + b) \ge 1,\quad \forall n
\end{aligned}
\]

\subsection{Giải bằng thư viện CVXOPT}

Dạng chuẩn:
\[
\min_{\mathbf{x}} \frac{1}{2}\mathbf{x}^T K \mathbf{x} + \mathbf{p}^T \mathbf{x}
\quad \text{s.t. } G\mathbf{x} \le \mathbf{h}
\]

Trong đó:
\[
\mathbf{x} =
\begin{bmatrix}
\mathbf{w} \\ b
\end{bmatrix}
\]

% =====================================================
\section{Tổng kết và Câu hỏi}

\subsection{Tổng kết}

\begin{itemize}
    \item Số biến: $M$
    \item Số ràng buộc: $N$
    \item Phù hợp khi $M \ll N$
    \item Áp dụng cho dữ liệu khả tách tuyến tính
\end{itemize}

\subsection{Câu hỏi}

\begin{enumerate}
    \item Véc-tơ $\mathbf{w}$ có ý nghĩa gì trong SVM?
    \item Vì sao nhãn $\{-1,+1\}$ thuận lợi?
    \item Độ rộng của lề bằng bao nhiêu?
    \item Viết dạng ma trận của bài toán gốc.
\end{enumerate}

% =====================================================
\section*{Tài liệu tham khảo}

\begin{itemize}
    \item C. M. Bishop, \textit{Pattern Recognition and Machine Learning}, Springer.
    \item N. Cristianini, J. Shawe-Taylor, \textit{An Introduction to Support Vector Machines}.
    \item \url{https://scikit-learn.org/stable/modules/svm.html}
\end{itemize}

% =====================================================
\section{Bài toán gốc}

Cho tập dữ liệu huấn luyện
\[
\{(x_n,t_n)\}_{n=1}^N,\quad
x_n \in \mathbb{R}^M,\; t_n \in \{-1,+1\}.
\]

Bài toán SVM hai lớp, khả tách tuyến tính được phát biểu như sau:
\begin{equation}
\begin{aligned}
(w^\ast,b^\ast)
&= \arg\min_{w,b} \; \frac{1}{2}\|w\|^2 \\
\text{s.t.}\quad
& t_n(w^T x_n + b) \ge 1,
\quad n=1,\dots,N.
\end{aligned}
\label{eq:primal}
\end{equation}

Đây là một bài toán tối ưu lồi với:
\begin{itemize}
\item Hàm mục tiêu lồi và khả vi
\item Các ràng buộc bất đẳng thức lồi
\end{itemize}

% =====================================================
\section{Kiến thức liên quan}

\subsection{Tối ưu lồi}
Bài toán \eqref{eq:primal} thuộc lớp \textit{convex optimization}.
Theo \cite{boyd}, nếu thỏa tiêu chuẩn Slater thì tồn tại \textit{strong duality}.

\subsection{Máy véc-tơ hỗ trợ}
SVM tìm siêu phẳng phân lớp có \textit{biên lớn nhất}, được xác định bởi các
\textit{véc-tơ hỗ trợ} (support vectors).

% =====================================================
\section{Bài toán đối ngẫu}

\subsection{Hàm Lagrangian}

Hàm Lagrangian của bài toán \eqref{eq:primal} là:
\begin{equation}
L(w,b,\alpha)
=
\frac{1}{2}\|w\|^2
-
\sum_{n=1}^N \alpha_n
\bigl[t_n(w^T x_n + b) - 1\bigr],
\label{eq:lagrangian}
\end{equation}
với
\[
\alpha_n \ge 0,\quad n=1,\dots,N.
\]

\subsection{Điều kiện KKT}

Bài toán thỏa hệ điều kiện KKT:
\begin{itemize}
\item \textbf{(KKT-1)} Điều kiện dừng:
\[
\nabla_{w,b} L(w,b,\alpha)=0
\]
\item \textbf{(KKT-2)} Ràng buộc gốc
\item \textbf{(KKT-3)} Ràng buộc đối ngẫu: $\alpha_n \ge 0$
\item \textbf{(KKT-4)} Điều kiện bù:
\[
\alpha_n[1-t_n(w^Tx_n+b)]=0
\]
\end{itemize}

% =====================================================
\section{Xây dựng hàm đối ngẫu}

Lấy đạo hàm theo $w$ và $b$:
\begin{align}
\frac{\partial L}{\partial w} &= w - \sum_{n=1}^N \alpha_n t_n x_n = 0
\label{eq:w}\\
\frac{\partial L}{\partial b} &= \sum_{n=1}^N \alpha_n t_n = 0
\label{eq:b}
\end{align}

Suy ra:
\begin{equation}
w = \sum_{n=1}^N \alpha_n t_n x_n.
\end{equation}

Thay vào Lagrangian, ta thu được hàm đối ngẫu:
\begin{equation}
g(\alpha)
=
\sum_{n=1}^N \alpha_n
-
\frac{1}{2}
\sum_{r=1}^N \sum_{c=1}^N
\alpha_r \alpha_c t_r t_c x_r^T x_c.
\end{equation}

% =====================================================
\section{Bài toán đối ngẫu}

Bài toán đối ngẫu tương đương:
\begin{equation}
\begin{aligned}
\alpha^\ast
&= \arg\min_{\alpha}
\;\frac{1}{2}\alpha^T K \alpha - \mathbf{1}^T \alpha \\
\text{s.t.}\quad
& \alpha_n \ge 0,\quad n=1,\dots,N,\\
& \sum_{n=1}^N \alpha_n t_n = 0,
\end{aligned}
\label{eq:dual}
\end{equation}
trong đó
\[
K_{rc} = t_r t_c x_r^T x_c.
\]

% =====================================================
\section{Tiêu chuẩn Slater}

Vì tồn tại $(w,b)$ sao cho
\[
t_n(w^Tx_n+b) > 1,\;\forall n,
\]
nên bài toán thỏa tiêu chuẩn Slater.
Do đó:
\[
\min_{w,b} \max_{\alpha} L(w,b,\alpha)
=
\max_{\alpha} \min_{w,b} L(w,b,\alpha).
\]

Suy ra \textbf{duality gap bằng 0}.

% =====================================================
\section{Công thức dự báo}

Với tập véc-tơ hỗ trợ $S = \{n : \alpha_n > 0\}$,
\begin{equation}
y(x)
=
\sum_{n\in S} \alpha_n t_n x_n^T x + b.
\end{equation}

Nhãn dự báo:
\[
\hat{y} = \operatorname{sign}(y(x)).
\]

% =====================================================
\section{Tổng kết}

\begin{itemize}
\item Bài toán SVM gốc là bài toán tối ưu lồi
\item Bài toán đối ngẫu có dạng quy hoạch toàn phương
\item Nghiệm phụ thuộc vào một số ít véc-tơ hỗ trợ
\item Huấn luyện và dự báo chỉ cần tích vô hướng
\end{itemize}

%------------------------------------------------
\section{Ôn lại: Hai lớp khả tách tuyến tính}

Cho tập dữ liệu huấn luyện
\[
\{(x_n, t_n)\}_{n=1}^N, \quad x_n \in \mathbb{R}^M, \; t_n \in \{-1, +1\}.
\]

Bài toán SVM hard-margin được phát biểu như sau:
\begin{equation}
\begin{aligned}
\min_{w,b} \quad & \frac{1}{2}\|w\|^2 \\
\text{s.t.} \quad & t_n(w^T x_n + b) \ge 1,\quad n=1,\dots,N.
\end{aligned}
\end{equation}

Mô hình này chỉ áp dụng khi dữ liệu khả tách tuyến tính.

%------------------------------------------------
\section{Giới thiệu bài toán không khả tách tuyến tính}

Trong thực tế, dữ liệu thường \textbf{không khả tách tuyến tính}.
Khi đó:
\begin{itemize}
    \item Tập nghiệm khả thi của hard-margin là rỗng.
    \item Không tồn tại $w,b$ thỏa tất cả các ràng buộc.
\end{itemize}

Do đó, cần mở rộng mô hình bằng cách cho phép một số điểm vi phạm ràng buộc.

%------------------------------------------------
\section{Nguyên tắc Soft Margin}

Ý tưởng chính:
\begin{enumerate}
    \item Nới lỏng ràng buộc bằng biến phạt $\xi_n$.
    \item Phạt các điểm nằm sai vị trí thông qua hàm mục tiêu.
\end{enumerate}

Mô hình này được gọi là \textbf{Soft Margin SVM}.

%------------------------------------------------
\section{Bài toán gốc với lề mềm}

\subsection{Ràng buộc mới}

\begin{align}
t_n(w^T x_n + b) &\ge 1 - \xi_n, \quad n=1,\dots,N, \\
\xi_n &\ge 0.
\end{align}

\subsection{Hàm mục tiêu mới}

\begin{equation}
f_0(w,b,\xi) =
\frac{1}{2}\|w\|^2 + C \sum_{n=1}^N \xi_n,
\end{equation}
trong đó $C > 0$ là siêu tham số điều chỉnh mức phạt.

\subsection{Bài toán tối ưu}

\begin{equation}
\begin{aligned}
\min_{w,b,\xi} \quad &
\frac{1}{2}\|w\|^2 + C \sum_{n=1}^N \xi_n \\
\text{s.t.} \quad &
t_n(w^T x_n + b) \ge 1 - \xi_n, \\
& \xi_n \ge 0,\quad n=1,\dots,N.
\end{aligned}
\end{equation}

%------------------------------------------------
\section{Bài toán đối ngẫu}

\subsection{Hàm Lagrangian}

\begin{equation}
\begin{aligned}
L(w,b,\xi,\alpha,\mu) &=
\frac{1}{2}\|w\|^2 + C\sum_{n=1}^N \xi_n \\
&\quad - \sum_{n=1}^N \alpha_n[t_n(w^T x_n + b)-1+\xi_n]
- \sum_{n=1}^N \mu_n \xi_n.
\end{aligned}
\end{equation}

\subsection{Điều kiện KKT}

\begin{align}
w &= \sum_{n=1}^N \alpha_n t_n x_n, \\
\sum_{n=1}^N \alpha_n t_n &= 0, \\
0 &\le \alpha_n \le C.
\end{align}

\subsection{Bài toán đối ngẫu}

\begin{equation}
\begin{aligned}
\min_{\alpha} \quad &
\frac{1}{2}\sum_{r=1}^N\sum_{c=1}^N
\alpha_r \alpha_c t_r t_c x_r^T x_c
- \sum_{n=1}^N \alpha_n \\
\text{s.t.} \quad &
0 \le \alpha_n \le C, \\
& \sum_{n=1}^N \alpha_n t_n = 0.
\end{aligned}
\end{equation}

%------------------------------------------------
\section{Công thức dự báo}

Sau khi tìm được $\alpha$ và $b$, hàm quyết định là:
\begin{equation}
y(x) = \sum_{n \in S} \alpha_n t_n x_n^T x + b,
\end{equation}
trong đó $S$ là tập các véc-tơ hỗ trợ.

Nhãn dự báo:
\[
\text{label} = \mathrm{sign}(y(x)).
\]

%------------------------------------------------
\section{Cài đặt với CVXOPT}

Bài toán đối ngẫu có dạng chuẩn:
\begin{equation}
\min_{\alpha} \quad
\frac{1}{2}\alpha^T K \alpha + p^T \alpha
\quad \text{s.t.} \quad
G\alpha \le h,\; A\alpha = b.
\end{equation}

Các ràng buộc hộp $0 \le \alpha_n \le C$ được mã hóa trong ma trận $G$ và $h$.

%------------------------------------------------
\section{Kết luận}

Bài báo đã trình bày:
\begin{itemize}
    \item Mô hình SVM soft-margin cho dữ liệu không khả tách tuyến tính.
    \item Dẫn xuất bài toán đối ngẫu và điều kiện KKT.
    \item Công thức dự báo và hướng cài đặt bằng CVXOPT.
\end{itemize}

Soft Margin SVM là nền tảng quan trọng cho các phương pháp kernel và SVM phi tuyến.

\section{Giới thiệu}
SVM là phương pháp học có giám sát, nổi bật nhờ khả năng tổng quát hóa tốt.
Ý tưởng chính của SVM là tìm siêu phẳng phân tách hai lớp dữ liệu với biên lớn nhất.

Khi dữ liệu không phân tách tuyến tính, SVM có thể được mở rộng thông qua
\textit{phương pháp kernel}.

\section{SVM hai lớp với lề mềm}
Xét tập huấn luyện $\{(x_i,t_i)\}_{i=1}^N$ với $t_i \in \{-1,+1\}$.
Bài toán đối ngẫu của SVM lề mềm được viết dưới dạng:

\begin{equation}
\alpha^* = \arg\min_{\alpha}
\frac{1}{2}\alpha^T K \alpha + p^T \alpha
\end{equation}

với các ràng buộc:
\begin{equation}
G\alpha \le h, \qquad A\alpha = b
\end{equation}

Trong đó, ma trận kernel $K$ được xác định bởi tích vô hướng giữa các điểm dữ liệu.

\subsection{Dự báo}
Giá trị bias $b$ được ước lượng bởi:
\begin{equation}
b = \frac{1}{N_M}
\left(
t_M - K_{MS}[\alpha_S \odot t_S]
\right)^T \mathbf{1}
\end{equation}

Hàm dự báo:
\begin{equation}
y = K_{BS}[\alpha_S \odot t_S] + b
\end{equation}

Nhãn dự đoán:
\begin{equation}
\text{label} = \text{sign}(y)
\end{equation}

\section{Khi đường biên giới phi tuyến}
Trong nhiều bài toán thực tế, dữ liệu không thể phân tách tuyến tính.
Giải pháp là ánh xạ dữ liệu thông qua hàm trích đặc trưng:
\[
\Phi: \mathbb{R}^d \rightarrow \mathcal{H}
\]

Tuy nhiên, việc tính trực tiếp $\Phi(x)$ có thể tốn kém hoặc không khả thi
khi không gian đặc trưng có số chiều rất lớn hoặc vô hạn.

\section{Phương pháp Kernel}
Phương pháp kernel cho phép tính:
\[
\langle \Phi(x_i), \Phi(x_j) \rangle
\]
mà không cần biết tường minh $\Phi(x)$, thông qua một hàm kernel:
\[
k(x_i,x_j)
\]

\subsection{Điều kiện Mercer}
Một hàm $k(x_i,x_j)$ là kernel hợp lệ nếu:
\begin{itemize}
\item Đối xứng: $k(x_i,x_j) = k(x_j,x_i)$
\item Bán định dương:
\[
\sum_{i=1}^N \sum_{j=1}^N c_i c_j k(x_i,x_j) \ge 0
\]
\end{itemize}

\section{Huấn luyện và dự báo với Kernel}
Ma trận Gram kernel:
\begin{equation}
K_{Gram} =
\begin{bmatrix}
k(x_1,x_1) & \cdots & k(x_1,x_N)\\
\vdots & \ddots & \vdots\\
k(x_N,x_1) & \cdots & k(x_N,x_N)
\end{bmatrix}
\end{equation}

Việc sử dụng kernel đảm bảo bài toán tối ưu là lồi và có nghiệm toàn cục.

\section{Các kernel thông dụng}
Một số kernel phổ biến trong thực tế:

\begin{itemize}
\item \textbf{Linear}:
\[
k(x,x') = x^T x'
\]

\item \textbf{Polynomial}:
\[
k(x,x') = (\gamma x^T x' + r)^d
\]

\item \textbf{RBF (Gaussian)}:
\[
k(x,x') = \exp(-\gamma \|x-x'\|^2)
\]

\item \textbf{Sigmoid}:
\[
k(x,x') = \tanh(\gamma x^T x' + r)
\]
\end{itemize}

Kernel RBF tương ứng với không gian đặc trưng vô hạn chiều.

\section{Thiết kế Kernel}
Việc thiết kế kernel phụ thuộc mạnh vào kiến thức miền (domain knowledge),
với mục tiêu:
\begin{itemize}
\item $k(x_i,x_j)$ lớn nếu $x_i, x_j$ cùng lớp
\item $k(x_i,x_j)$ nhỏ nếu khác lớp
\end{itemize}

\section{Minh họa}
Các thí nghiệm với kernel đa thức và kernel RBF cho thấy khả năng
phi tuyến hóa đường biên phân lớp một cách hiệu quả.

\section{Kết luận}
Bài báo đã trình bày SVM với lề mềm và phương pháp kernel, cho phép mở rộng
khả năng phân lớp sang các bài toán phi tuyến. Phương pháp kernel giúp tránh
việc tính toán trực tiếp không gian đặc trưng, đồng thời vẫn đảm bảo tính tối ưu
của bài toán.

\section{Giới thiệu}
Trong nhiều bài toán học máy, dữ liệu đầu vào thường có số chiều rất lớn. Điều này dẫn đến các vấn đề như:
\begin{itemize}
    \item Độ phức tạp tính toán tăng cao;
    \item Khoảng cách giữa các điểm dữ liệu trở nên kém ý nghĩa;
    \item Nguy cơ quá khớp (overfitting).
\end{itemize}

Hiện tượng này thường được gọi là \emph{Curse of Dimensionality}. PCA được đề xuất nhằm giải quyết vấn đề trên bằng cách thu giảm số chiều dữ liệu.

\section{Mô tả bài toán}
Giả sử tập dữ liệu đầu vào:
\[
X =
\begin{bmatrix}
x_{1,1} & x_{1,2} & \cdots & x_{1,D} \\
x_{2,1} & x_{2,2} & \cdots & x_{2,D} \\
\vdots  & \vdots  & \ddots & \vdots  \\
x_{N,1} & x_{N,2} & \cdots & x_{N,D}
\end{bmatrix}
\]
trong đó:
\begin{itemize}
    \item $X \in \mathbb{R}^{N \times D}$;
    \item $D$ rất lớn và các chiều có tương quan với nhau.
\end{itemize}

\textbf{Mục tiêu:}
\begin{enumerate}
    \item Giảm số chiều từ $D$ xuống $M$ với $M \ll D$;
    \item Các đặc trưng mới không còn tương quan tuyến tính.
\end{enumerate}

\section{Kiến thức toán học liên quan}
\subsection{Phương sai và hiệp phương sai}
Trung bình của dữ liệu:
\[
\mu = \frac{1}{N}\sum_{n=1}^{N} x_n
\]

Dữ liệu được chuẩn hóa:
\[
z_n = x_n - \mu
\]

Ma trận hiệp phương sai:
\[
S = \frac{1}{N}\sum_{n=1}^{N}(x_n - \mu)(x_n - \mu)^T
\]

\subsection{Eigenvalue và Eigenvector}
Với ma trận vuông $A$, bài toán eigen:
\[
Au = \lambda u
\]
trong đó $u$ là eigenvector và $\lambda$ là eigenvalue.

\section{Cơ sở lý luận của PCA}
PCA có thể được nhìn theo hai cách:
\begin{itemize}
    \item Cực đại hóa phương sai của dữ liệu sau khi chiếu;
    \item Cực tiểu hóa sai số phục hồi dữ liệu.
\end{itemize}

Hai cách tiếp cận này là tương đương về mặt toán học.

\section{Cực đại hóa phương sai}
Với một vectơ đơn vị $u$, phương sai của dữ liệu khi chiếu lên $u$ là:
\[
\sigma^2 = u^T S u
\]

Bài toán tối ưu:
\[
\max_{u} \quad u^T S u
\quad \text{s.t.} \quad u^T u = 1
\]

Sử dụng nhân tử Lagrange dẫn đến:
\[
Su = \lambda u
\]

Do đó:
\begin{itemize}
    \item Các trục chính của PCA là các eigenvector của $S$;
    \item Phương sai tương ứng là các eigenvalue.
\end{itemize}

\section{Thu giảm số chiều}
Chọn $M$ eigenvector tương ứng với $M$ eigenvalue lớn nhất, tạo thành ma trận:
\[
\hat{U} = [u_1, u_2, \dots, u_M]
\]

Chiếu dữ liệu:
\[
X_{\text{PCA}} = (X - \mu^T)\hat{U}
\]

Phục hồi xấp xỉ:
\[
\hat{X} = \mu^T + X_{\text{PCA}}\hat{U}^T
\]

\section{PCA qua API}
Ví dụ PCA trong \texttt{scikit-learn}:
\begin{verbatim}
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
pca.fit(X)
print(pca.explained_variance_ratio_)
\end{verbatim}

\section{Singular Value Decomposition (SVD)}
Phân rã SVD:
\[
X = U S V^T
\]

\begin{itemize}
    \item PCA thực hiện eigen-decomposition trên ma trận hiệp phương sai;
    \item SVD phân rã trực tiếp trên ma trận dữ liệu và có độ ổn định số cao hơn.
\end{itemize}

\section{Ứng dụng của PCA}
\begin{itemize}
    \item Nén dữ liệu;
    \item Trực quan hóa dữ liệu nhiều chiều;
    \item Tiền xử lý cho học máy;
    \item Nhận dạng mẫu và xử lý ảnh.
\end{itemize}

\section{Kết luận}
PCA là một phương pháp mạnh mẽ và hiệu quả cho bài toán thu giảm số chiều. Dựa trên nền tảng đại số tuyến tính, PCA giúp loại bỏ nhiễu, giảm độ phức tạp và cải thiện hiệu suất của các mô hình học máy.

% ==========================================================
\section{Giới thiệu về LDA}

Linear Discriminant Analysis (LDA) là một phương pháp thu giảm số chiều có giám sát,
trong đó thông tin nhãn của dữ liệu được sử dụng để tìm ra không gian chiếu
sao cho các lớp được phân tách tốt nhất.

\subsection{Đầu vào}

Cho tập dữ liệu:
\[
X =
\begin{bmatrix}
x_{1,1} & x_{1,2} & \cdots & x_{1,D} \\
x_{2,1} & x_{2,2} & \cdots & x_{2,D} \\
\vdots  & \vdots  & \ddots & \vdots  \\
x_{N,1} & x_{N,2} & \cdots & x_{N,D}
\end{bmatrix},
\quad
t =
\begin{bmatrix}
t_1 \\ t_2 \\ \vdots \\ t_N
\end{bmatrix}
\]

Trong đó:
\begin{itemize}
  \item $X \in \mathbb{R}^{N \times D}$, với $D$ thường rất lớn.
  \item $t_k \in \{1,2,\ldots,C\}$ là nhãn lớp của điểm dữ liệu thứ $k$.
\end{itemize}

\subsection{Mục tiêu}

Mục tiêu của LDA là:
\begin{enumerate}
  \item Giảm số chiều từ $D$ xuống $M$, với $M \le C - 1$.
  \item Dữ liệu sau khi chiếu có độ phân tách giữa các lớp là lớn nhất.
\end{enumerate}

% ==========================================================
\section{LDA qua API}

Ví dụ sử dụng \texttt{Scikit-learn}:

\begin{verbatim}
from sklearn import datasets
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

iris = datasets.load_iris()
X = iris.data
y = iris.target

lda = LinearDiscriminantAnalysis(n_components=2)
X_r = lda.fit(X, y).transform(X)
\end{verbatim}

% ==========================================================
\section{Bài toán tối ưu}

\subsection{Tâm của mỗi lớp}

Với lớp $k$:
\[
\mathbf{m}_k = \frac{1}{N_k} \sum_{n \in C_k} \mathbf{x}_n
\]

\subsection{Between-class scatter matrix}

\[
S_B = (\mathbf{m}_2 - \mathbf{m}_1)(\mathbf{m}_2 - \mathbf{m}_1)^T
\]

\subsection{Within-class scatter matrix}

\[
S_W = \sum_{k=1}^{C} \sum_{n \in C_k}
(\mathbf{x}_n - \mathbf{m}_k)(\mathbf{x}_n - \mathbf{m}_k)^T
\]

\subsection{Hàm mục tiêu của Fisher}

\[
J(\mathbf{w}) =
\frac{\mathbf{w}^T S_B \mathbf{w}}
     {\mathbf{w}^T S_W \mathbf{w}}
\]

Mục tiêu:
\[
\mathbf{w}^* = \arg\max_{\mathbf{w}} J(\mathbf{w})
\]

% ==========================================================
\section{Tìm nghiệm}

Giải bài toán tối ưu dẫn đến phương trình trị riêng:
\[
S_W^{-1} S_B \mathbf{w} = \lambda \mathbf{w}
\]

Hướng chiếu tối ưu là:
\[
\mathbf{w} \propto S_W^{-1}(\mathbf{m}_2 - \mathbf{m}_1)
\]

% ==========================================================
\section{Trường hợp có $C$ lớp}

\subsection{Hàm mục tiêu tổng quát}

\[
J(W) =
\frac{\text{trace}(W^T S_B W)}
     {\text{trace}(W^T S_W W)}
\]

\subsection{Số chiều tối đa}

Số chiều tối đa có thể chọn là:
\[
M \le C - 1
\]

Do ma trận $S_B$ có hạng tối đa là $C-1$.

\subsection{Giải thuật LDA}

\begin{enumerate}
  \item Tính $S_B$ và $S_W$.
  \item Tính $A = S_W^{-1} S_B$.
  \item Thực hiện SVD hoặc eigen-decomposition.
  \item Chọn $M$ eigenvector tương ứng với eigenvalue lớn nhất.
  \item Chiếu dữ liệu: $\hat{X} = (X - m^T)W$.
\end{enumerate}

% ==========================================================
\section{Kết luận}

Linear Discriminant Analysis là một phương pháp mạnh mẽ cho thu giảm số chiều có giám sát,
đặc biệt hiệu quả khi mục tiêu là phân loại.
LDA không chỉ giúp giảm độ phức tạp tính toán mà còn cải thiện hiệu năng của mô hình học máy.


\section{Introduction}

Single learning models often suffer from limited representational power or high
sensitivity to training data. These issues can lead to high bias, high variance,
or both. Ensemble methods address these limitations by combining multiple
learners into a single predictive model, following the principle known as the
\emph{wisdom of the crowd}.

% --------------------
\section{Bias--Variance Perspective}

Prediction error can be decomposed into bias and variance. Bias results from
overly simplistic assumptions, while variance reflects sensitivity to training
data fluctuations. Ensemble learning aims to reduce variance by averaging
predictions of multiple weakly correlated models. For regression, the variance
of an ensemble predictor can be approximated as
\[
\mathrm{Var}\left(
\frac{1}{M} \sum_{m=1}^{M} \hat{y}^{(m)}
\right)
\approx
\frac{1}{M^2} \sum_{m=1}^{M} \mathrm{Var}(\hat{y}^{(m)}).
\]

% --------------------
\section{Bagging (Bootstrap Aggregating)}

Bagging is designed to reduce variance, particularly for unstable learners such
as decision trees.

\subsection{Method Description}

Given a training dataset
\[
D = \{(x_i, y_i)\}_{i=1}^{n},
\]
Bagging constructs an ensemble of $M$ models as follows:
\begin{enumerate}[label=\arabic*.]
\item Draw $M$ bootstrap datasets $D_1, D_2, \dots, D_M$ by sampling $n$ points
with replacement from $D$.
\item Train a base learner on each bootstrap dataset to obtain models
$h_1, h_2, \dots, h_M$.
\item Combine predictions of all models:
\[
\hat{y}(x) =
\begin{cases}
\frac{1}{M}\sum_{m=1}^{M} h_m(x), & \text{regression}, \\
\text{majority vote}, & \text{classification}.
\end{cases}
\]
\end{enumerate}

\subsection{Properties}

Bagging is simple, highly parallelizable, and effective at variance reduction.
However, it requires storing many models and results in slower inference.

% --------------------
\section{Random Forest}

Random Forest extends Bagging by introducing randomness in feature selection.
Each tree is trained on a bootstrap dataset, and at each split only a random
subset of features is considered.

\subsection{Training Procedure}

For each tree:
\begin{enumerate}[label=\arabic*.]
\item Sample a bootstrap dataset from the training set.
\item Grow a decision tree by recursively splitting nodes.
\item At each split, randomly select a subset of features
$F_{\text{sub}} \subset \{1,\dots,d\}$.
\item Choose the best split using only features in $F_{\text{sub}}$.
\end{enumerate}

Typical choices are $|F_{\text{sub}}|=\sqrt{d}$ for classification and
$|F_{\text{sub}}|=d/3$ for regression.

% --------------------
\section{Boosting}

Boosting methods train models sequentially, where each model focuses on samples
misclassified by previous ones. Unlike Bagging, Boosting can reduce both bias
and variance.

\subsection{AdaBoost}

For binary classification with $y_i \in \{-1,+1\}$, AdaBoost maintains a weight
distribution over training samples. At iteration $t$, a weak learner $h_t$ is
trained using weighted data. The final classifier is
\[
H(x) = \mathrm{sign}
\left(
\sum_{t=1}^{T} \alpha_t h_t(x)
\right),
\]
where $\alpha_t$ is determined by the weighted classification error of $h_t$.

\subsection{Gradient Boosting}

Gradient Boosting views ensemble construction as gradient descent in function
space. At each iteration, a new weak learner is fitted to the negative gradient
of the loss function with respect to current predictions.

% --------------------
\section{Voting and Stacking}

\subsection{Voting}

Voting combines predictions of multiple models using a fixed rule such as
majority voting or probability averaging. It is simple and often serves as a
strong baseline.

\subsection{Stacking}

Stacking trains a meta-learner on predictions of base models. To avoid
overfitting, cross-validation is used to generate out-of-fold predictions, which
are then used as inputs for the meta-model.

% --------------------
\section{Comparison and Practical Considerations}

Bagging is most effective for high-variance models, Boosting can significantly
improve accuracy but is sensitive to noise, and Stacking offers the greatest
flexibility at the cost of increased complexity. In practice, Random Forests
and Gradient Boosting are strong default choices for tabular data.

% --------------------
\section{Conclusion}

Ensemble methods provide a principled way to improve predictive performance by
combining multiple models. Understanding their assumptions and trade-offs is
essential for effective application in real-world machine learning problems.

\section{Introduction}

Genetic Algorithm (GA) is a metaheuristic optimization algorithm inspired
by the process of natural selection.
It was developed by John Holland in the 1970s and belongs to the broader class
of Evolutionary Algorithms (EA).

GA is particularly effective when:
\begin{itemize}
    \item The search space is large or complex
    \item The objective function is non-differentiable or discontinuous
    \item Multiple local optima exist
    \item Classical optimization techniques are ineffective
\end{itemize}

Unlike gradient-based methods, GA does not require derivative information
and performs a parallel exploration of the search space.

\section{Key Components of Genetic Algorithms}

\subsection{Representation (Encoding)}

A solution is encoded as a chromosome. Common encoding methods include:
\begin{itemize}
    \item \textbf{Binary encoding}: chromosomes consist of bits (0 or 1)
    \item \textbf{Real-valued encoding}: genes are real numbers
    \item \textbf{Permutation encoding}: chromosomes represent ordered sequences
    \item \textbf{Tree encoding}: solutions are tree structures (used in genetic programming)
\end{itemize}

\subsection{Fitness Function}

The fitness function $f(x)$ evaluates the quality of a solution $x$.
For minimization problems, a transformation is typically applied, such as:
\[
f_{\text{max}}(x) = \frac{1}{1 + f_{\text{min}}(x)}
\]

The fitness function should be computationally efficient, as it is evaluated
many times during the evolutionary process.

\subsection{Selection}

Selection chooses parent solutions based on fitness.
Popular methods include:
\begin{itemize}
    \item Roulette wheel selection
    \item Rank selection
    \item Tournament selection
    \item Elitism
\end{itemize}

Elitism ensures that the best individuals are preserved across generations.

\subsection{Crossover}

Crossover combines genetic material from two parents to produce offspring.
Common techniques include:
\begin{itemize}
    \item Single-point crossover
    \item Two-point crossover
    \item Uniform crossover
    \item Arithmetic crossover (for real-valued encoding)
\end{itemize}

\subsection{Mutation}

Mutation introduces random changes to maintain population diversity.
Typical mutation strategies include:
\begin{itemize}
    \item Bit flipping for binary encoding
    \item Gaussian or uniform noise for real-valued encoding
    \item Swap or inversion for permutation encoding
\end{itemize}

\section{Genetic Algorithm Framework}

A standard genetic algorithm follows these steps:
\begin{enumerate}
    \item Initialize a population of $N$ individuals
    \item Evaluate fitness of each individual
    \item Repeat until a termination condition is met:
    \begin{enumerate}
        \item Select parents based on fitness
        \item Apply crossover to generate offspring
        \item Apply mutation to offspring
        \item Evaluate fitness of new individuals
        \item Form the next generation (with optional elitism)
    \end{enumerate}
    \item Return the best solution found
\end{enumerate}

Termination conditions may include a maximum number of generations,
fitness convergence, stagnation, or time limits.

\section{Simple Example}

Consider maximizing the function:
\[
f(x) = x^2, \quad x \in \{0,1,\ldots,15\}
\]

Binary encoding with 4 bits is used.
An example initial population is shown in Table~\ref{tab:initpop}.

\begin{table}[h]
\centering
\caption{Initial population}
\label{tab:initpop}
\begin{tabular}{cccc}
\toprule
Individual & Binary & $x$ & $f(x)$ \\
\midrule
A & 0110 & 6 & 36 \\
B & 1001 & 9 & 81 \\
C & 0011 & 3 & 9 \\
D & 1100 & 12 & 144 \\
\bottomrule
\end{tabular}
\end{table}

After selection, crossover, and mutation, the population gradually
converges toward the optimal solution $x=15$.

\section{Parameters and Tuning}

Key parameters include:
\begin{itemize}
    \item Population size ($N$)
    \item Crossover probability ($p_c$)
    \item Mutation probability ($p_m$)
\end{itemize}

Typical values are:
\begin{itemize}
    \item $N = 20$--$200$
    \item $p_c = 0.6$--$0.9$
    \item $p_m = 0.001$--$0.1$
\end{itemize}

Parameter selection is problem-dependent and often requires empirical tuning.

\section{Advantages and Disadvantages}

\subsection{Advantages}
\begin{itemize}
    \item Global search capability
    \item No requirement for gradient information
    \item Parallelizable structure
    \item Flexible solution representation
\end{itemize}

\subsection{Disadvantages}
\begin{itemize}
    \item No guarantee of global optimality
    \item Computationally expensive
    \item Sensitive to parameter settings
    \item Risk of premature convergence
\end{itemize}

\section{Applications}

Genetic Algorithms have been successfully applied in:
\begin{itemize}
    \item Combinatorial optimization (TSP, scheduling)
    \item Machine learning (feature selection, hyperparameter tuning)
    \item Engineering design (antennas, circuits)
    \item Bioinformatics (protein structure prediction)
    \item Game AI and procedural content generation
\end{itemize}

\section{Variants and Extensions}

Popular GA variants include:
\begin{itemize}
    \item Real-Coded Genetic Algorithms (RCGA)
    \item Differential Evolution (DE)
    \item Genetic Programming (GP)
    \item Multi-objective Genetic Algorithms (e.g., NSGA-II)
\end{itemize}

These variants extend GA to continuous, programmatic,
and multi-objective optimization problems.

\section{Conclusion}

Genetic Algorithms provide a powerful and flexible optimization framework
for complex problems where traditional methods fail.
Although not guaranteed to find the global optimum,
proper encoding and parameter tuning enable GA to produce
high-quality approximate solutions efficiently.

\end{multicols}

% ==================================================
\end{document}
